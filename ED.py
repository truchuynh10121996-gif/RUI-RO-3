# app.py ‚Äî Streamlit PD + Ph√¢n t√≠ch Gemini (C·∫¨P NH·∫¨T TH∆Ø VI·ªÜN)

# =========================
# TH∆Ø VI·ªÜN B·∫ÆT BU·ªòC V√Ä B·ªî SUNG
# (C·∫ßn ƒë·∫£m b·∫£o c√°c g√≥i n√†y ƒë∆∞·ª£c c√†i ƒë·∫∑t, v√≠ d·ª• trong requirements.txt)
# =========================
from datetime import datetime
import os
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
# Th∆∞ vi·ªán Machine Learning v√† M√¥ h√¨nh
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    confusion_matrix,
    f1_score,
    accuracy_score,
    recall_score,
    precision_score,
    roc_auc_score,
    ConfusionMatrixDisplay,
)
# C√°c th∆∞ vi·ªán B·ªî SUNG theo y√™u c·∫ßu (n·∫øu ƒë∆∞·ª£c s·ª≠ d·ª•ng trong code sau n√†y)
# import xgboost as xgb
# import graphviz
# import statsmodels.api as sm

# =========================
# TH√äM TH∆Ø VI·ªÜN GOOGLE GEMINI V√Ä OPENAI (CHO T∆Ø∆†NG TH√çCH V·ªöI REQ C≈®)
# =========================
try:
    from google import genai
    from google.genai.errors import APIError
    _GEMINI_OK = True
except Exception:
    genai = None
    APIError = Exception
    _GEMINI_OK = False

try:
    from openai import OpenAI
    _OPENAI_OK = True
except Exception:
    OpenAI = None
    _OPENAI_OK = False


MODEL_NAME = "gemini-2.5-flash" # Model m·∫°nh m·∫Ω v√† hi·ªáu qu·∫£ cho ph√¢n t√≠ch vƒÉn b·∫£n

# =========================
# FEATURE LABELS - CH·ªà S·ªê T√ÄI CH√çNH
# =========================
# NOTE: C·∫≠p nh·∫≠t t√™n ch·ªâ s·ªë cho ph√π h·ª£p v·ªõi nghi·ªáp v·ª• th·ª±c t·∫ø c·ªßa ng√¢n h√†ng
FEATURE_LABELS = {
    "X_1": "Bi√™n l·ª£i nhu·∫≠n g·ªôp",
    "X_2": "Bi√™n l·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø",
    "X_3": "ROA (L·ª£i nhu·∫≠n tr√™n t·ªïng t√†i s·∫£n)",
    "X_4": "ROE (L·ª£i nhu·∫≠n tr√™n v·ªën ch·ªß s·ªü h·ªØu)",
    "X_5": "T·ª∑ s·ªë n·ª£ tr√™n t·ªïng t√†i s·∫£n",
    "X_6": "T·ª∑ s·ªë n·ª£ tr√™n v·ªën ch·ªß s·ªü h·ªØu",
    "X_7": "T·ª∑ s·ªë thanh to√°n hi·ªán h√†nh",
    "X_8": "T·ª∑ s·ªë thanh to√°n nhanh",
    "X_9": "Kh·∫£ nƒÉng thanh to√°n l√£i vay",
    "X_10": "Kh·∫£ nƒÉng thanh to√°n n·ª£ g·ªëc",
    "X_11": "T·ª∑ s·ªë ti·ªÅn m·∫∑t tr√™n v·ªën ch·ªß s·ªü h·ªØu",
    "X_12": "V√≤ng quay h√†ng t·ªìn kho",
    "X_13": "K·ª≥ thu ti·ªÅn b√¨nh qu√¢n (ng√†y)",
    "X_14": "Hi·ªáu su·∫•t s·ª≠ d·ª•ng t√†i s·∫£n",
}

def get_feature_display_name(feature_code):
    """Tr·∫£ v·ªÅ t√™n hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß: 'X1 ‚Äì Bi√™n l·ª£i nhu·∫≠n g·ªôp'"""
    if feature_code in FEATURE_LABELS:
        # Chuy·ªÉn X_1 th√†nh X1
        code_display = feature_code.replace("_", "")
        return f"{code_display} ‚Äì {FEATURE_LABELS[feature_code]}"
    return feature_code

# =========================
# H√ÄM G·ªåI GEMINI API
# =========================

def get_ai_analysis(data_payload: dict, api_key: str) -> str:
    """
    S·ª≠ d·ª•ng Gemini API ƒë·ªÉ ph√¢n t√≠ch ch·ªâ s·ªë t√†i ch√≠nh.
    """
    if not _GEMINI_OK:
        return "L·ªói: Thi·∫øu th∆∞ vi·ªán google-genai (c·∫ßn c√†i ƒë·∫∑t: pip install google-genai)."

    client = genai.Client(api_key=api_key)

    sys_prompt = (
        "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch t√≠n d·ª•ng doanh nghi·ªáp t·∫°i ng√¢n h√†ng. "
        "Ph√¢n t√≠ch to√†n di·ªán d·ª±a tr√™n 14 ch·ªâ s·ªë t√†i ch√≠nh (X1..X14). "
        "N√™u r√µ: (1) Kh·∫£ nƒÉng sinh l·ªùi, (2) Thanh kho·∫£n, (3) C∆° c·∫•u n·ª£, (4) Hi·ªáu qu·∫£ ho·∫°t ƒë·ªông. "
        "K·∫øt th√∫c b·∫±ng khuy·∫øn ngh·ªã in hoa: CHO VAY ho·∫∑c KH√îNG CHO VAY, k√®m 2‚Äì3 ƒëi·ªÅu ki·ªán n·∫øu CHO VAY. "
        "Vi·∫øt b·∫±ng ti·∫øng Vi·ªát s√∫c t√≠ch, chuy√™n nghi·ªáp."
    )
    
    user_prompt = "B·ªô ch·ªâ s·ªë X1..X14 c·∫ßn ph√¢n t√≠ch:\n" + str(data_payload) + "\n\nH√£y ph√¢n t√≠ch v√† ƒë∆∞a ra khuy·∫øn ngh·ªã."

    try:
        response = client.models.generate_content(
            model=MODEL_NAME,
            contents=[
                {"role": "user", "parts": [{"text": sys_prompt + "\n\n" + user_prompt}]}
            ],
            config={"system_instruction": sys_prompt}
        )
        return response.text
    except APIError as e:
        return f"L·ªói g·ªçi API Gemini: {e}"
    except Exception as e:
        return f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"


# =========================
# T√çNH X1..X14 T·ª™ 3 SHEET (CDKT/BCTN/LCTT)
# =========================

# Alias c√°c d√≤ng quan tr·ªçng trong t·ª´ng sheet
ALIAS_IS = {
    "doanh_thu_thuan": ["Doanh thu thu·∫ßn", "Doanh thu b√°n h√†ng", "Doanh thu thu·∫ßn v·ªÅ b√°n h√†ng v√† cung c·∫•p d·ªãch v·ª•"],
    "gia_von": ["Gi√° v·ªën h√†ng b√°n"],
    "loi_nhuan_gop": ["L·ª£i nhu·∫≠n g·ªôp"],
    "chi_phi_lai_vay": ["Chi ph√≠ l√£i vay", "Chi ph√≠ t√†i ch√≠nh (trong ƒë√≥: chi ph√≠ l√£i vay)"],
    "loi_nhuan_truoc_thue": ["T·ªïng l·ª£i nhu·∫≠n k·∫ø to√°n tr∆∞·ªõc thu·∫ø", "L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø", "L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø thu nh·∫≠p DN"],
}
ALIAS_BS = {
    "tong_tai_san": ["T·ªïng t√†i s·∫£n"],
    "von_chu_so_huu": ["V·ªën ch·ªß s·ªü h·ªØu", "V·ªën CSH"],
    "no_phai_tra": ["N·ª£ ph·∫£i tr·∫£"],
    "tai_san_ngan_han": ["T√†i s·∫£n ng·∫Øn h·∫°n"],
    "no_ngan_han": ["N·ª£ ng·∫Øn h·∫°n"],
    "hang_ton_kho": ["H√†ng t·ªìn kho"],
    "tien_tdt": ["Ti·ªÅn v√† c√°c kho·∫£n t∆∞∆°ng ƒë∆∞∆°ng ti·ªÅn", "Ti·ªÅn v√† t∆∞∆°ng ƒë∆∞∆°ng ti·ªÅn"],
    "phai_thu_kh": ["Ph·∫£i thu ng·∫Øn h·∫°n c·ªßa kh√°ch h√†ng", "Ph·∫£i thu kh√°ch h√†ng"],
    "no_dai_han_den_han": ["N·ª£ d√†i h·∫°n ƒë·∫øn h·∫°n tr·∫£", "N·ª£ d√†i h·∫°n ƒë·∫øn h·∫°n"],
}
ALIAS_CF = {
    "khau_hao": ["Kh·∫•u hao TSCƒê", "Kh·∫•u hao", "Chi ph√≠ kh·∫•u hao"],
}

def _pick_year_cols(df: pd.DataFrame):
    """Ch·ªçn 2 c·ªôt nƒÉm g·∫ßn nh·∫•t t·ª´ sheet (∆∞u ti√™n c·ªôt c√≥ nh√£n l√† nƒÉm)."""
    numeric_years = []
    for c in df.columns[1:]:
        try:
            y = int(float(str(c).strip()))
            if 1990 <= y <= 2100:
                numeric_years.append((y, c))
        except Exception:
            continue
    if numeric_years:
        numeric_years.sort(key=lambda x: x[0])
        return numeric_years[-2][1], numeric_years[-1][1]
    # fallback: 2 c·ªôt cu·ªëi
    cols = df.columns[-2:]
    return cols[0], cols[1]

def _get_row_vals(df: pd.DataFrame, aliases: list[str]):
    """T√¨m d√≤ng theo alias (contains, kh√¥ng ph√¢n bi·ªát hoa/th∆∞·ªùng). Tr·∫£ v·ªÅ (prev, cur) theo 2 c·ªôt nƒÉm g·∫ßn nh·∫•t."""
    label_col = df.columns[0]
    prev_col, cur_col = _pick_year_cols(df)
    mask = False
    for alias in aliases:
        mask = mask | df[label_col].astype(str).str.contains(alias, case=False, na=False)
    rows = df[mask]
    if rows.empty:
        return np.nan, np.nan
    row = rows.iloc[0]

    def to_num(x):
        try:
            return float(str(x).replace(",", "").replace(" ", ""))
        except Exception:
            return np.nan

    return to_num(row[prev_col]), to_num(row[cur_col])

def compute_ratios_from_three_sheets(xlsx_file) -> pd.DataFrame:
    """ƒê·ªçc 3 sheet CDKT/BCTN/LCTT v√† t√≠nh X1..X14 theo y√™u c·∫ßu."""
    # ƒê·ªçc 3 sheet; c·∫ßn openpyxl trong requirements
    bs = pd.read_excel(xlsx_file, sheet_name="CDKT", engine="openpyxl")
    is_ = pd.read_excel(xlsx_file, sheet_name="BCTN", engine="openpyxl")
    cf = pd.read_excel(xlsx_file, sheet_name="LCTT", engine="openpyxl")

    # ---- KQKD (BCTN)
    DTT_prev, DTT_cur    = _get_row_vals(is_, ALIAS_IS["doanh_thu_thuan"])
    GVHB_prev, GVHB_cur = _get_row_vals(is_, ALIAS_IS["gia_von"])
    LNG_prev, LNG_cur    = _get_row_vals(is_, ALIAS_IS["loi_nhuan_gop"])
    LNTT_prev, LNTT_cur = _get_row_vals(is_, ALIAS_IS["loi_nhuan_truoc_thue"])
    LV_prev, LV_cur      = _get_row_vals(is_, ALIAS_IS["chi_phi_lai_vay"])

    # ---- CƒêKT (CDKT)
    TTS_prev, TTS_cur      = _get_row_vals(bs, ALIAS_BS["tong_tai_san"])
    VCSH_prev, VCSH_cur    = _get_row_vals(bs, ALIAS_BS["von_chu_so_huu"])
    NPT_prev, NPT_cur      = _get_row_vals(bs, ALIAS_BS["no_phai_tra"])
    TSNH_prev, TSNH_cur    = _get_row_vals(bs, ALIAS_BS["tai_san_ngan_han"])
    NNH_prev, NNH_cur      = _get_row_vals(bs, ALIAS_BS["no_ngan_han"])
    HTK_prev, HTK_cur      = _get_row_vals(bs, ALIAS_BS["hang_ton_kho"])
    Tien_prev, Tien_cur    = _get_row_vals(bs, ALIAS_BS["tien_tdt"])
    KPT_prev, KPT_cur      = _get_row_vals(bs, ALIAS_BS["phai_thu_kh"])
    NDH_prev, NDH_cur      = _get_row_vals(bs, ALIAS_BS["no_dai_han_den_han"])

    # ---- LCTT (LCTT) ‚Äì l·∫•y Kh·∫•u hao n·∫øu c√≥
    KH_prev, KH_cur = _get_row_vals(cf, ALIAS_CF["khau_hao"])

    # Chu·∫©n ho√° s·ªë √¢m th∆∞·ªùng th·∫•y ·ªü GVHB, chi ph√≠ l√£i vay, kh·∫•u hao
    if pd.notna(GVHB_cur): GVHB_cur = abs(GVHB_cur)
    if pd.notna(LV_cur):    LV_cur    = abs(LV_cur)
    if pd.notna(KH_cur):    KH_cur    = abs(KH_cur)

    # Trung b√¨nh ƒë·∫ßu/cu·ªëi k·ª≥
    def avg(a, b):
        if pd.isna(a) and pd.isna(b): return np.nan
        if pd.isna(a): return b
        if pd.isna(b): return a
        return (a + b) / 2.0
    TTS_avg  = avg(TTS_cur,  TTS_prev)
    VCSH_avg = avg(VCSH_cur, VCSH_prev)
    HTK_avg  = avg(HTK_cur,  HTK_prev)
    KPT_avg  = avg(KPT_cur,  KPT_prev)

    # EBIT ~ LNTT + chi ph√≠ l√£i vay (n·∫øu thi·∫øu EBIT ri√™ng)
    EBIT_cur = (LNTT_cur + LV_cur) if (pd.notna(LNTT_cur) and pd.notna(LV_cur)) else np.nan
    # N·ª£ d√†i h·∫°n ƒë·∫øn h·∫°n tr·∫£: c√≥ file kh√¥ng ghi -> set 0
    NDH_cur = 0.0 if pd.isna(NDH_cur) else NDH_cur

    def div(a, b):
        return np.nan if (b is None or pd.isna(b) or b == 0) else a / b

    # ==== T√çNH X1..X14 ====
    X1  = div(LNG_cur, DTT_cur)                      # Bi√™n LN g·ªôp
    X2  = div(LNTT_cur, DTT_cur)                     # Bi√™n LNTT
    X3  = div(LNTT_cur, TTS_avg)                     # ROA (tr∆∞·ªõc thu·∫ø)
    X4  = div(LNTT_cur, VCSH_avg)                    # ROE (tr∆∞·ªõc thu·∫ø)
    X5  = div(NPT_cur,  TTS_cur)                     # N·ª£/T√†i s·∫£n
    X6  = div(NPT_cur,  VCSH_cur)                    # N·ª£/VCSH
    X7  = div(TSNH_cur, NNH_cur)                     # Thanh to√°n hi·ªán h√†nh
    X8  = div((TSNH_cur - HTK_cur) if pd.notna(TSNH_cur) and pd.notna(HTK_cur) else np.nan, NNH_cur)  # Nhanh
    X9  = div(EBIT_cur, LV_cur)                      # Kh·∫£ nƒÉng tr·∫£ l√£i
    X10 = div((EBIT_cur + (KH_cur if pd.notna(KH_cur) else 0.0)),
              (LV_cur + NDH_cur) if pd.notna(LV_cur) else np.nan)  # Kh·∫£ nƒÉng tr·∫£ n·ª£ g·ªëc
    X11 = div(Tien_cur, VCSH_cur)                     # Ti·ªÅn/VCSH
    X12 = div(GVHB_cur, HTK_avg)                     # V√≤ng quay HTK
    turnover = div(DTT_cur, KPT_avg)                # V√≤ng quay ph·∫£i thu
    X13 = div(365.0, turnover) if pd.notna(turnover) and turnover != 0 else np.nan  # K·ª≥ thu ti·ªÅn BQ
    X14 = div(DTT_cur, TTS_avg)                      # Hi·ªáu su·∫•t s·ª≠ d·ª•ng t√†i s·∫£n

    ratios = pd.DataFrame([[X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14]],
                          columns=[f"X_{i}" for i in range(1, 15)])
    return ratios

# =========================
# UI HELPER FUNCTIONS
# =========================
def load_css(file_path):
    """Load CSS file into Streamlit"""
    try:
        with open(file_path) as f:
            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
    except FileNotFoundError:
        st.warning(f"CSS file not found: {file_path}")

def render_header():
    """Render Agribank-style header with logo"""
    try:
        # Create header with logo
        st.markdown("""
        <div class="agribank-header">
            <img src="data:image/jpeg;base64,{}" width="80" height="80" alt="Agribank Logo">
            <h1>ƒê√°nh gi√° r·ªßi ro t√≠n d·ª•ng kh√°ch h√†ng doanh nghi·ªáp</h1>
        </div>
        """.format(_get_logo_base64()), unsafe_allow_html=True)
    except Exception:
        # Fallback without logo
        st.markdown("""
        <div class="agribank-header">
            <h1>ƒê√°nh gi√° r·ªßi ro t√≠n d·ª•ng kh√°ch h√†ng doanh nghi·ªáp</h1>
        </div>
        """, unsafe_allow_html=True)

def _get_logo_base64():
    """Get base64 encoded logo"""
    import base64
    try:
        with open("logo-agribank.jpg", "rb") as f:
            return base64.b64encode(f.read()).decode()
    except Exception:
        return ""

def render_metric_card(title, value, icon="üìä"):
    """Render a metric card with styling"""
    st.markdown(f"""
    <div class="metric-card">
        <h3>{icon} {title}</h3>
        <p>{value}</p>
    </div>
    """, unsafe_allow_html=True)

# =========================
# UI & TRAIN MODEL
# =========================
np.random.seed(0)

# Load CSS theme
load_css("ui/theme.css")

# Render header
render_header()

# Hi·ªÉn th·ªã tr·∫°ng th√°i th∆∞ vi·ªán AI
st.caption("üîé Tr·∫°ng th√°i Gemini: " + ("‚úÖ s·∫µn s√†ng (c·∫ßn 'GEMINI_API_KEY' trong Secrets)" if _GEMINI_OK else "‚ö†Ô∏è Thi·∫øu th∆∞ vi·ªán google-genai."))

# Load d·ªØ li·ªáu hu·∫•n luy·ªán (CSV c√≥ default, X_1..X_14)
try:
    df = pd.read_csv('DATASET.csv', encoding='latin-1')
except Exception:
    df = None

uploaded_file = st.file_uploader("T·∫£i CSV d·ªØ li·ªáu hu·∫•n luy·ªán", type=['csv'])
if uploaded_file is not None:
    df = pd.read_csv(uploaded_file, encoding='latin-1')

if df is None:
    st.info("H√£y t·∫£i file CSV hu·∫•n luy·ªán (c√≥ c·ªôt 'default' v√† X_1...X_14).")
    st.stop()

# Ki·ªÉm tra c·ªôt c·∫ßn thi·∫øt
required_cols = ['default'] + [f"X_{i}" for i in range(1, 15)]
missing = [c for c in required_cols if c not in df.columns]
if missing:
    st.error(f"Thi·∫øu c·ªôt: {missing}")
    st.stop()

st.write(df[[f"X_{i}" for i in range(1, 15)]].describe())

# Train model
X = df.drop(columns=['default'])
y = df['default'].astype(int)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
model = LogisticRegression(random_state=42, max_iter=1000, class_weight="balanced", solver="lbfgs")
model.fit(X_train, y_train)

# D·ª± b√°o & ƒë√°nh gi√°
y_pred_in = model.predict(X_train)
y_proba_in = model.predict_proba(X_train)[:, 1]
y_pred_out = model.predict(X_test)
y_proba_out = model.predict_proba(X_test)[:, 1]

metrics_in = {
    "accuracy_in": accuracy_score(y_train, y_pred_in),
    "precision_in": precision_score(y_train, y_pred_in, zero_division=0),
    "recall_in": recall_score(y_train, y_pred_in, zero_division=0),
    "f1_in": f1_score(y_train, y_pred_in, zero_division=0),
    "auc_in": roc_auc_score(y_train, y_proba_in),
}
metrics_out = {
    "accuracy_out": accuracy_score(y_test, y_pred_out),
    "precision_out": precision_score(y_test, y_pred_out, zero_division=0),
    "recall_out": recall_score(y_test, y_pred_out, zero_division=0),
    "f1_out": f1_score(y_test, y_pred_out, zero_division=0),
    "auc_out": roc_auc_score(y_test, y_proba_out),
}

# =========================
# TABS LAYOUT - 3 TAB NGANG
# =========================
tab1, tab2, tab3 = st.tabs([
    "üìà S·ª≠ d·ª•ng m√¥ h√¨nh d·ª± b√°o",
    "üìä Ph√¢n t√≠ch d·ªØ li·ªáu",
    "üìö T√†i li·ªáu & H∆∞·ªõng d·∫´n"
])

# TAB 1: S·ª¨ D·ª§NG M√î H√åNH D·ª∞ B√ÅO (Default tab)
with tab1:
    st.subheader("S·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ d·ª± b√°o & ph√¢n t√≠ch AI (3 sheet)")
    st.caption("File ph·∫£i c√≥ ƒë·ªß 3 sheet: **CDKT ; BCTN ; LCTT**")

    up_xlsx = st.file_uploader("T·∫£i ho_so_dn.xlsx", type=["xlsx"], key="ho_so_dn")
    if up_xlsx is not None:
        # T√≠nh X1..X14 t·ª´ 3 sheet
        try:
            ratios_df = compute_ratios_from_three_sheets(up_xlsx)
        except Exception as e:
            st.error(f"L·ªói t√≠nh X1‚Ä¶X14: {e}")
            st.stop()

        st.markdown("### K·∫øt qu·∫£ t√≠nh to√°n 14 ch·ªâ s·ªë t√†i ch√≠nh")

        # Create a display dataframe with readable labels
        display_df = ratios_df.copy()
        display_df.columns = [get_feature_display_name(col) for col in display_df.columns]

        # Display in a styled container
        st.markdown('<div class="feature-table">', unsafe_allow_html=True)
        st.dataframe(display_df.style.format("{:.4f}"), use_container_width=True)
        st.markdown('</div>', unsafe_allow_html=True)

        # T·∫°o payload data cho AI
        data_for_ai = ratios_df.iloc[0].to_dict()

        # Metric cards for key indicators
        st.markdown("### üìä C√°c ch·ªâ s·ªë quan tr·ªçng")
        col1, col2, col3 = st.columns(3)

        with col1:
            render_metric_card(
                "Bi√™n l·ª£i nhu·∫≠n g·ªôp (X1)",
                f"{ratios_df['X_1'].iloc[0]:.2%}" if pd.notna(ratios_df['X_1'].iloc[0]) else "N/A",
                "üí∞"
            )
        with col2:
            render_metric_card(
                "ROA (X3)",
                f"{ratios_df['X_3'].iloc[0]:.2%}" if pd.notna(ratios_df['X_3'].iloc[0]) else "N/A",
                "üìà"
            )
        with col3:
            render_metric_card(
                "T·ª∑ s·ªë thanh to√°n (X7)",
                f"{ratios_df['X_7'].iloc[0]:.2f}" if pd.notna(ratios_df['X_7'].iloc[0]) else "N/A",
                "üíµ"
            )

        # (Tu·ª≥ ch·ªçn) d·ª± b√°o PD n·∫øu m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán ƒë√∫ng c·∫•u tr√∫c X_1..X_14
        if set(X.columns) == set(ratios_df.columns):
            with st.expander("üîç X√°c su·∫•t v·ª° n·ª£ d·ª± b√°o (n·∫øu ƒë√£ hu·∫•n luy·ªán ·ªü tr√™n)"):
                try:
                    probs = model.predict_proba(ratios_df[X.columns])[:, 1]
                    preds = (probs >= 0.5).astype(int)
                    show = ratios_df.copy()
                    show["pd"] = probs
                    show["pred_default"] = preds
                    st.dataframe(show.style.format({"pd": "{:.3f}"}), use_container_width=True)
                except Exception as e:
                    st.warning(f"Kh√¥ng d·ª± b√°o ƒë∆∞·ª£c PD: {e}")

        # Gemini Ph√¢n t√≠ch & khuy·∫øn ngh·ªã
        st.markdown("### ü§ñ Ph√¢n t√≠ch AI & ƒë·ªÅ xu·∫•t CHO VAY/KH√îNG CHO VAY")

        # Th√™m c√°c ch·ªâ s·ªë PD n·∫øu ƒë√£ t√≠nh ƒë∆∞·ª£c v√†o payload
        if 'probs' in locals():
            data_for_ai['PD_Probability'] = probs[0]
            data_for_ai['PD_Prediction'] = "Default (V·ª° n·ª£)" if preds[0] == 1 else "Non-Default (Kh√¥ng v·ª° n·ª£)"

        if st.button("üöÄ Y√™u c·∫ßu AI Ph√¢n t√≠ch", use_container_width=True):
            api_key = st.secrets.get("GEMINI_API_KEY")

            if api_key:
                with st.spinner('ƒêang g·ª≠i d·ªØ li·ªáu v√† ch·ªù Gemini ph√¢n t√≠ch...'):
                    ai_result = get_ai_analysis(data_for_ai, api_key)
                    st.markdown("**K·∫øt qu·∫£ Ph√¢n t√≠ch t·ª´ Gemini AI:**")
                    st.info(ai_result)
            else:
                st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API. Vui l√≤ng c·∫•u h√¨nh Kh√≥a **'GEMINI_API_KEY'** trong Streamlit Secrets.")

    else:
        st.info("H√£y t·∫£i **ho_so_dn.xlsx** (ƒë·ªß 3 sheet) ƒë·ªÉ t√≠nh X1‚Ä¶X14, d·ª± b√°o PD v√† ph√¢n t√≠ch AI.")

# TAB 2: PH√ÇN T√çCH D·ªÆ LI·ªÜU
with tab2:
    st.subheader("Ph√¢n t√≠ch d·ªØ li·ªáu & X√¢y d·ª±ng m√¥ h√¨nh")

    st.write("##### 1) Hi·ªÉn th·ªã d·ªØ li·ªáu")
    col_a, col_b = st.columns(2)
    with col_a:
        st.caption("D·ªØ li·ªáu ƒë·∫ßu")
        st.dataframe(df.head(3), use_container_width=True)
    with col_b:
        st.caption("D·ªØ li·ªáu cu·ªëi")
        st.dataframe(df.tail(3), use_container_width=True)

    st.write("##### 2) Tr·ª±c quan h√≥a d·ªØ li·ªáu")

    # Feature selection
    col = st.selectbox(
        'Ch·ªçn bi·∫øn X mu·ªën ph√¢n t√≠ch',
        options=[f"X_{i}" for i in range(1, 15)],
        format_func=lambda x: get_feature_display_name(x),
        index=0
    )

    if col in df.columns:
        try:
            # Plotly scatter plot with logistic curve
            st.markdown('<div class="chart-container">', unsafe_allow_html=True)

            # Create scatter plot
            fig = px.scatter(
                df,
                x=col,
                y='default',
                opacity=0.5,
                labels={col: get_feature_display_name(col), 'default': 'X√°c su·∫•t v·ª° n·ª£'},
                color='default',
                color_continuous_scale=['#D4AF37', '#800000']
            )

            # Add logistic regression curve
            x_range = np.linspace(df[col].min(), df[col].max(), 100)
            X_temp = df[[col]].copy()
            y_temp = df['default']
            lr_temp = LogisticRegression(max_iter=1000)
            lr_temp.fit(X_temp, y_temp)
            x_test = pd.DataFrame({col: x_range})
            y_curve = lr_temp.predict_proba(x_test)[:, 1]

            fig.add_trace(
                go.Scatter(
                    x=x_range,
                    y=y_curve,
                    mode='lines',
                    name='Logistic Regression',
                    line=dict(color='#800000', width=3)
                )
            )

            # Update layout with Plotly 5 compatible syntax
            fig.update_layout(
                title={
                    'text': f'Ph√¢n t√≠ch {get_feature_display_name(col)}',
                    'x': 0.5,
                    'xanchor': 'center'
                },
                xaxis_title=get_feature_display_name(col),
                yaxis_title='X√°c su·∫•t v·ª° n·ª£',
                height=500,
                hovermode='closest'
            )

            st.plotly_chart(fig, use_container_width=True)
            st.markdown('</div>', unsafe_allow_html=True)

        except Exception as e:
            st.error(f"L·ªói khi v·∫Ω bi·ªÉu ƒë·ªì: {e}")
    else:
        st.warning("Bi·∫øn kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu.")

    st.write("##### 3) K·∫øt qu·∫£ ƒë√°nh gi√° m√¥ h√¨nh")

    # Display metrics in cards
    col1, col2, col3, col4, col5 = st.columns(5)
    with col1:
        render_metric_card("Accuracy (Test)", f"{metrics_out['accuracy_out']:.3f}", "üéØ")
    with col2:
        render_metric_card("Precision (Test)", f"{metrics_out['precision_out']:.3f}", "‚úÖ")
    with col3:
        render_metric_card("Recall (Test)", f"{metrics_out['recall_out']:.3f}", "üîç")
    with col4:
        render_metric_card("F1 Score (Test)", f"{metrics_out['f1_out']:.3f}", "‚öñÔ∏è")
    with col5:
        render_metric_card("AUC (Test)", f"{metrics_out['auc_out']:.3f}", "üìä")

    # Full metrics table
    with st.expander("Xem chi ti·∫øt c√°c ch·ªâ s·ªë ƒë√°nh gi√°"):
        dt = pd.DataFrame([metrics_in | metrics_out])
        st.dataframe(dt, use_container_width=True)

    st.write("##### 4) Ma tr·∫≠n nh·∫ßm l·∫´n (Test Set)")
    cm = confusion_matrix(y_test, y_pred_out)

    # Create Plotly heatmap for confusion matrix
    st.markdown('<div class="chart-container">', unsafe_allow_html=True)
    fig_cm = px.imshow(
        cm,
        labels=dict(x="D·ª± b√°o", y="Th·ª±c t·∫ø", color="S·ªë l∆∞·ª£ng"),
        x=['Non-Default', 'Default'],
        y=['Non-Default', 'Default'],
        color_continuous_scale=['#FAFAFA', '#800000'],
        text_auto=True
    )
    fig_cm.update_layout(
        title={
            'text': 'Ma tr·∫≠n nh·∫ßm l·∫´n - Test Set',
            'x': 0.5,
            'xanchor': 'center'
        },
        height=400
    )
    st.plotly_chart(fig_cm, use_container_width=True)
    st.markdown('</div>', unsafe_allow_html=True)

    # Additional analysis charts
    st.write("##### 5) Bi·ªÉu ƒë·ªì ph√¢n t√≠ch b·ªï sung")

    chart_type = st.radio(
        "Ch·ªçn lo·∫°i bi·ªÉu ƒë·ªì",
        ["Ph√¢n b·ªë ch·ªâ s·ªë", "So s√°nh gi√° tr·ªã trung b√¨nh", "Correlation Matrix"],
        horizontal=True
    )

    if chart_type == "Ph√¢n b·ªë ch·ªâ s·ªë":
        selected_feature = st.selectbox(
            'Ch·ªçn ch·ªâ s·ªë',
            options=[f"X_{i}" for i in range(1, 15)],
            format_func=lambda x: get_feature_display_name(x),
            key="hist_select"
        )
        if selected_feature in df.columns:
            st.markdown('<div class="chart-container">', unsafe_allow_html=True)
            fig_hist = px.histogram(
                df,
                x=selected_feature,
                color='default',
                marginal="box",
                nbins=30,
                labels={selected_feature: get_feature_display_name(selected_feature)},
                color_discrete_map={0: '#D4AF37', 1: '#800000'}
            )
            fig_hist.update_layout(
                title={
                    'text': f'Ph√¢n b·ªë {get_feature_display_name(selected_feature)}',
                    'x': 0.5,
                    'xanchor': 'center'
                },
                height=500
            )
            st.plotly_chart(fig_hist, use_container_width=True)
            st.markdown('</div>', unsafe_allow_html=True)

    elif chart_type == "So s√°nh gi√° tr·ªã trung b√¨nh":
        # Calculate means by default status
        means_df = df.groupby('default')[[f"X_{i}" for i in range(1, 15)]].mean().T
        means_df.columns = ['Non-Default', 'Default']
        means_df['Feature'] = [get_feature_display_name(f"X_{i}") for i in range(1, 15)]

        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        fig_bar = px.bar(
            means_df,
            x='Feature',
            y=['Non-Default', 'Default'],
            barmode='group',
            labels={'value': 'Gi√° tr·ªã trung b√¨nh', 'Feature': 'Ch·ªâ s·ªë'},
            color_discrete_map={'Non-Default': '#D4AF37', 'Default': '#800000'}
        )
        fig_bar.update_layout(
            title={
                'text': 'So s√°nh gi√° tr·ªã trung b√¨nh c√°c ch·ªâ s·ªë theo tr·∫°ng th√°i',
                'x': 0.5,
                'xanchor': 'center'
            },
            height=500,
            xaxis_tickangle=-45
        )
        st.plotly_chart(fig_bar, use_container_width=True)
        st.markdown('</div>', unsafe_allow_html=True)

    elif chart_type == "Correlation Matrix":
        # Calculate correlation matrix
        corr_matrix = df[[f"X_{i}" for i in range(1, 15)]].corr()

        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        fig_corr = px.imshow(
            corr_matrix,
            labels=dict(color="Correlation"),
            x=[get_feature_display_name(f"X_{i}") for i in range(1, 15)],
            y=[get_feature_display_name(f"X_{i}") for i in range(1, 15)],
            color_continuous_scale='RdBu_r',
            zmin=-1,
            zmax=1,
            text_auto='.2f'
        )
        fig_corr.update_layout(
            title={
                'text': 'Ma tr·∫≠n t∆∞∆°ng quan gi·ªØa c√°c ch·ªâ s·ªë',
                'x': 0.5,
                'xanchor': 'center'
            },
            height=700,
            xaxis_tickangle=-45
        )
        st.plotly_chart(fig_corr, use_container_width=True)
        st.markdown('</div>', unsafe_allow_html=True)

# TAB 3: T√ÄI LI·ªÜU & H∆Ø·ªöNG D·∫™N
with tab3:
    st.subheader("T√†i li·ªáu & H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng")

    st.markdown("### üìñ Gi·ªõi thi·ªáu h·ªá th·ªëng")
    st.markdown("""
    **H·ªá th·ªëng ƒë√°nh gi√° r·ªßi ro t√≠n d·ª•ng kh√°ch h√†ng doanh nghi·ªáp** l√† c√¥ng c·ª• h·ªó tr·ª£ quy·∫øt ƒë·ªãnh
    cho vay d·ª±a tr√™n ph√¢n t√≠ch 14 ch·ªâ s·ªë t√†i ch√≠nh quan tr·ªçng.
    """)

    # Display images
    st.markdown("### üñºÔ∏è Minh h·ªça m√¥ h√¨nh")
    for img in ["hinh2.jpg", "LogReg_1.png", "hinh3.png"]:
        try:
            st.image(img, use_column_width=True)
        except Exception:
            st.info(f"H√¨nh minh h·ªça {img} s·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t sau")

    st.markdown("### üìä Chi ti·∫øt 14 ch·ªâ s·ªë t√†i ch√≠nh")

    # Create a nice table with feature descriptions
    features_info = []
    for i in range(1, 15):
        feature_code = f"X_{i}"
        features_info.append({
            "M√£": f"X{i}",
            "T√™n ch·ªâ s·ªë": FEATURE_LABELS[feature_code],
            "Nh√≥m": _get_feature_group(i)
        })

    features_df = pd.DataFrame(features_info)
    st.dataframe(features_df, use_container_width=True, hide_index=True)

    st.markdown("### üìù H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng")
    st.markdown("""
    #### B∆∞·ªõc 1: Chu·∫©n b·ªã d·ªØ li·ªáu
    - Chu·∫©n b·ªã file Excel (.xlsx) ch·ª©a 3 sheet:
        - **CDKT**: C√¢n ƒë·ªëi k·∫ø to√°n
        - **BCTN**: B√°o c√°o thu nh·∫≠p
        - **LCTT**: L∆∞u chuy·ªÉn ti·ªÅn t·ªá

    #### B∆∞·ªõc 2: T·∫£i file v√† ph√¢n t√≠ch
    - Chuy·ªÉn sang tab **"S·ª≠ d·ª•ng m√¥ h√¨nh d·ª± b√°o"**
    - T·∫£i file Excel l√™n h·ªá th·ªëng
    - H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông t√≠nh to√°n 14 ch·ªâ s·ªë t√†i ch√≠nh

    #### B∆∞·ªõc 3: Xem k·∫øt qu·∫£
    - Xem b·∫£ng k·∫øt qu·∫£ 14 ch·ªâ s·ªë v·ªõi t√™n ƒë·∫ßy ƒë·ªß
    - Xem c√°c ch·ªâ s·ªë quan tr·ªçng ƒë∆∞·ª£c highlight
    - Xem x√°c su·∫•t v·ª° n·ª£ d·ª± b√°o

    #### B∆∞·ªõc 4: Ph√¢n t√≠ch AI
    - Nh·∫•n n√∫t **"Y√™u c·∫ßu AI Ph√¢n t√≠ch"**
    - ƒê·ªçc k·∫øt qu·∫£ ph√¢n t√≠ch v√† khuy·∫øn ngh·ªã t·ª´ Gemini AI
    - Ra quy·∫øt ƒë·ªãnh cho vay d·ª±a tr√™n ph√¢n t√≠ch t·ªïng h·ª£p
    """)

    st.markdown("### ‚öôÔ∏è C·∫•u h√¨nh API")
    st.info("""
    ƒê·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng ph√¢n t√≠ch AI, c·∫ßn c·∫•u h√¨nh **GEMINI_API_KEY** trong Streamlit Secrets.
    Li√™n h·ªá qu·∫£n tr·ªã vi√™n h·ªá th·ªëng ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£.
    """)

def _get_feature_group(index):
    """Helper function to categorize features into groups"""
    if index in [1, 2, 3, 4]:
        return "Kh·∫£ nƒÉng sinh l·ªùi"
    elif index in [5, 6]:
        return "C∆° c·∫•u n·ª£"
    elif index in [7, 8, 9, 10, 11]:
        return "Thanh kho·∫£n"
    elif index in [12, 13, 14]:
        return "Hi·ªáu qu·∫£ ho·∫°t ƒë·ªông"
    return "Kh√°c"
