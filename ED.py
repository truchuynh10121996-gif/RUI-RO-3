# app.py ‚Äî Streamlit PD + Ph√¢n t√≠ch Gemini (C·∫¨P NH·∫¨T GIAO DI·ªÜN)

# =========================
# TH∆Ø VI·ªÜN B·∫ÆT BU·ªòC V√Ä B·ªî SUNG
# =========================
from datetime import datetime
import os
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
# Th∆∞ vi·ªán Machine Learning v√† M√¥ h√¨nh
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    confusion_matrix,
    f1_score,
    accuracy_score,
    recall_score,
    precision_score,
    roc_auc_score,
    ConfusionMatrixDisplay,
)
# Th∆∞ vi·ªán AI (ƒë√£ gi·ªØ nguy√™n)
try:
    from google import genai
    from google.genai.errors import APIError
    _GEMINI_OK = True
except Exception:
    genai = None
    APIError = Exception
    _GEMINI_OK = False

try:
    from openai import OpenAI
    _OPENAI_OK = True
except Exception:
    OpenAI = None
    _OPENAI_OK = False


MODEL_NAME = "gemini-2.5-flash" 

# =========================
# H√ÄM G·ªåI GEMINI API
# =========================

def get_ai_analysis(data_payload: dict, api_key: str) -> str:
    """
    S·ª≠ d·ª•ng Gemini API ƒë·ªÉ ph√¢n t√≠ch ch·ªâ s·ªë t√†i ch√≠nh.
    """
    if not _GEMINI_OK:
        return "L·ªói: Thi·∫øu th∆∞ vi·ªán google-genai (c·∫ßn c√†i ƒë·∫∑t: pip install google-genai)."

    client = genai.Client(api_key=api_key)

    sys_prompt = (
        "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch t√≠n d·ª•ng doanh nghi·ªáp t·∫°i ng√¢n h√†ng. "
        "Ph√¢n t√≠ch to√†n di·ªán d·ª±a tr√™n 14 ch·ªâ s·ªë t√†i ch√≠nh (X1..X14). "
        "N√™u r√µ: (1) Kh·∫£ nƒÉng sinh l·ªùi, (2) Thanh kho·∫£n, (3) C∆° c·∫•u n·ª£, (4) Hi·ªáu qu·∫£ ho·∫°t ƒë·ªông. "
        "K·∫øt th√∫c b·∫±ng khuy·∫øn ngh·ªã in hoa: CHO VAY ho·∫∑c KH√îNG CHO VAY, k√®m 2‚Äì3 ƒëi·ªÅu ki·ªán n·∫øu CHO VAY. "
        "Vi·∫øt b·∫±ng ti·∫øng Vi·ªát s√∫c t√≠ch, chuy√™n nghi·ªáp."
    )
    
    user_prompt = "B·ªô ch·ªâ s·ªë X1..X14 c·∫ßn ph√¢n t√≠ch:\n" + str(data_payload) + "\n\nH√£y ph√¢n t√≠ch v√† ƒë∆∞a ra khuy·∫øn ngh·ªã."

    try:
        response = client.models.generate_content(
            model=MODEL_NAME,
            contents=[
                {"role": "user", "parts": [{"text": sys_prompt + "\n\n" + user_prompt}]}
            ],
            config={"system_instruction": sys_prompt}
        )
        return response.text
    except APIError as e:
        return f"L·ªói g·ªçi API Gemini: {e}"
    except Exception as e:
        return f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"


# =========================
# T√çNH X1..X14 T·ª™ 3 SHEET (CDKT/BCTN/LCTT)
# =========================

# Alias c√°c d√≤ng quan tr·ªçng trong t·ª´ng sheet
ALIAS_IS = {
    "doanh_thu_thuan": ["Doanh thu thu·∫ßn", "Doanh thu b√°n h√†ng", "Doanh thu thu·∫ßn v·ªÅ b√°n h√†ng v√† cung c·∫•p d·ªãch v·ª•"],
    "gia_von": ["Gi√° v·ªën h√†ng b√°n"],
    "loi_nhuan_gop": ["L·ª£i nhu·∫≠n g·ªôp"],
    "chi_phi_lai_vay": ["Chi ph√≠ l√£i vay", "Chi ph√≠ t√†i ch√≠nh (trong ƒë√≥: chi ph√≠ l√£i vay)"],
    "loi_nhuan_truoc_thue": ["T·ªïng l·ª£i nhu·∫≠n k·∫ø to√°n tr∆∞·ªõc thu·∫ø", "L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø", "L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø thu nh·∫≠p DN"],
}
ALIAS_BS = {
    "tong_tai_san": ["T·ªïng t√†i s·∫£n"],
    "von_chu_so_huu": ["V·ªën ch·ªß s·ªü h·ªØu", "V·ªën CSH"],
    "no_phai_tra": ["N·ª£ ph·∫£i tr·∫£"],
    "tai_san_ngan_han": ["T√†i s·∫£n ng·∫Øn h·∫°n"],
    "no_ngan_han": ["N·ª£ ng·∫Øn h·∫°n"],
    "hang_ton_kho": ["H√†ng t·ªìn kho"],
    "tien_tdt": ["Ti·ªÅn v√† c√°c kho·∫£n t∆∞∆°ng ƒë∆∞∆°ng ti·ªÅn", "Ti·ªÅn v√† t∆∞∆°ng ƒë∆∞∆°ng ti·ªÅn"],
    "phai_thu_kh": ["Ph·∫£i thu ng·∫Øn h·∫°n c·ªßa kh√°ch h√†ng", "Ph·∫£i thu kh√°ch h√†ng"],
    "no_dai_han_den_han": ["N·ª£ d√†i h·∫°n ƒë·∫øn h·∫°n tr·∫£", "N·ª£ d√†i h·∫°n ƒë·∫øn h·∫°n"],
}
ALIAS_CF = {
    "khau_hao": ["Kh·∫•u hao TSCƒê", "Kh·∫•u hao", "Chi ph√≠ kh·∫•u hao"],
}

def _pick_year_cols(df: pd.DataFrame):
    """Ch·ªçn 2 c·ªôt nƒÉm g·∫ßn nh·∫•t t·ª´ sheet (∆∞u ti√™n c·ªôt c√≥ nh√£n l√† nƒÉm)."""
    numeric_years = []
    for c in df.columns[1:]:
        try:
            y = int(float(str(c).strip()))
            if 1990 <= y <= 2100:
                numeric_years.append((y, c))
        except Exception:
            continue
    if numeric_years:
        numeric_years.sort(key=lambda x: x[0])
        return numeric_years[-2][1], numeric_years[-1][1]
    # fallback: 2 c·ªôt cu·ªëi
    cols = df.columns[-2:]
    return cols[0], cols[1]

def _get_row_vals(df: pd.DataFrame, aliases: list[str]):
    """T√¨m d√≤ng theo alias (contains, kh√¥ng ph√¢n bi·ªát hoa/th∆∞·ªùng). Tr·∫£ v·ªÅ (prev, cur) theo 2 c·ªôt nƒÉm g·∫ßn nh·∫•t."""
    label_col = df.columns[0]
    prev_col, cur_col = _pick_year_cols(df)
    mask = False
    for alias in aliases:
        mask = mask | df[label_col].astype(str).str.contains(alias, case=False, na=False)
    rows = df[mask]
    if rows.empty:
        return np.nan, np.nan
    row = rows.iloc[0]

    def to_num(x):
        try:
            return float(str(x).replace(",", "").replace(" ", ""))
        except Exception:
            return np.nan

    return to_num(row[prev_col]), to_num(row[cur_col])

def compute_ratios_from_three_sheets(xlsx_file) -> pd.DataFrame:
    """ƒê·ªçc 3 sheet CDKT/BCTN/LCTT v√† t√≠nh X1..X14 theo y√™u c·∫ßu."""
    # ƒê·ªçc 3 sheet; c·∫ßn openpyxl trong requirements
    bs = pd.read_excel(xlsx_file, sheet_name="CDKT", engine="openpyxl")
    is_ = pd.read_excel(xlsx_file, sheet_name="BCTN", engine="openpyxl")
    cf = pd.read_excel(xlsx_file, sheet_name="LCTT", engine="openpyxl")

    # ---- KQKD (BCTN)
    DTT_prev, DTT_cur    = _get_row_vals(is_, ALIAS_IS["doanh_thu_thuan"])
    GVHB_prev, GVHB_cur = _get_row_vals(is_, ALIAS_IS["gia_von"])
    LNG_prev, LNG_cur    = _get_row_vals(is_, ALIAS_IS["loi_nhuan_gop"])
    LNTT_prev, LNTT_cur = _get_row_vals(is_, ALIAS_IS["loi_nhuan_truoc_thue"])
    LV_prev, LV_cur      = _get_row_vals(is_, ALIAS_IS["chi_phi_lai_vay"])

    # ---- CƒêKT (CDKT)
    TTS_prev, TTS_cur      = _get_row_vals(bs, ALIAS_BS["tong_tai_san"])
    VCSH_prev, VCSH_cur    = _get_row_vals(bs, ALIAS_BS["von_chu_so_huu"])
    NPT_prev, NPT_cur      = _get_row_vals(bs, ALIAS_BS["no_phai_tra"])
    TSNH_prev, TSNH_cur    = _get_row_vals(bs, ALIAS_BS["tai_san_ngan_han"])
    NNH_prev, NNH_cur      = _get_row_vals(bs, ALIAS_BS["no_ngan_han"])
    HTK_prev, HTK_cur      = _get_row_vals(bs, ALIAS_BS["hang_ton_kho"])
    Tien_prev, Tien_cur    = _get_row_vals(bs, ALIAS_BS["tien_tdt"])
    KPT_prev, KPT_cur      = _get_row_vals(bs, ALIAS_BS["phai_thu_kh"])
    NDH_prev, NDH_cur      = _get_row_vals(bs, ALIAS_BS["no_dai_han_den_han"])

    # ---- LCTT (LCTT) ‚Äì l·∫•y Kh·∫•u hao n·∫øu c√≥
    KH_prev, KH_cur = _get_row_vals(cf, ALIAS_CF["khau_hao"])

    # Chu·∫©n ho√° s·ªë √¢m th∆∞·ªùng th·∫•y ·ªü GVHB, chi ph√≠ l√£i vay, kh·∫•u hao
    if pd.notna(GVHB_cur): GVHB_cur = abs(GVHB_cur)
    if pd.notna(LV_cur):    LV_cur    = abs(LV_cur)
    if pd.notna(KH_cur):    KH_cur    = abs(KH_cur)

    # Trung b√¨nh ƒë·∫ßu/cu·ªëi k·ª≥
    def avg(a, b):
        if pd.isna(a) and pd.isna(b): return np.nan
        if pd.isna(a): return b
        if pd.isna(b): return a
        return (a + b) / 2.0
    TTS_avg  = avg(TTS_cur,  TTS_prev)
    VCSH_avg = avg(VCSH_cur, VCSH_prev)
    HTK_avg  = avg(HTK_cur,  HTK_prev)
    KPT_avg  = avg(KPT_cur,  KPT_prev)

    # EBIT ~ LNTT + chi ph√≠ l√£i vay (n·∫øu thi·∫øu EBIT ri√™ng)
    EBIT_cur = (LNTT_cur + LV_cur) if (pd.notna(LNTT_cur) and pd.notna(LV_cur)) else np.nan
    # N·ª£ d√†i h·∫°n ƒë·∫øn h·∫°n tr·∫£: c√≥ file kh√¥ng ghi -> set 0
    NDH_cur = 0.0 if pd.isna(NDH_cur) else NDH_cur

    def div(a, b):
        return np.nan if (b is None or pd.isna(b) or b == 0) else a / b

    # ==== T√çNH X1..X14 ====
    X1  = div(LNG_cur, DTT_cur)                      # Bi√™n LN g·ªôp
    X2  = div(LNTT_cur, DTT_cur)                     # Bi√™n LNTT
    X3  = div(LNTT_cur, TTS_avg)                     # ROA (tr∆∞·ªõc thu·∫ø)
    X4  = div(LNTT_cur, VCSH_avg)                    # ROE (tr∆∞·ªõc thu·∫ø)
    X5  = div(NPT_cur,  TTS_cur)                     # N·ª£/T√†i s·∫£n
    X6  = div(NPT_cur,  VCSH_cur)                    # N·ª£/VCSH
    X7  = div(TSNH_cur, NNH_cur)                     # Thanh to√°n hi·ªán h√†nh
    X8  = div((TSNH_cur - HTK_cur) if pd.notna(TSNH_cur) and pd.notna(HTK_cur) else np.nan, NNH_cur)  # Nhanh
    X9  = div(EBIT_cur, LV_cur)                      # Kh·∫£ nƒÉng tr·∫£ l√£i
    X10 = div((EBIT_cur + (KH_cur if pd.notna(KH_cur) else 0.0)),
              (LV_cur + NDH_cur) if pd.notna(LV_cur) else np.nan)  # Kh·∫£ nƒÉng tr·∫£ n·ª£ g·ªëc
    X11 = div(Tien_cur, VCSH_cur)                     # Ti·ªÅn/VCSH
    X12 = div(GVHB_cur, HTK_avg)                     # V√≤ng quay HTK
    turnover = div(DTT_cur, KPT_avg)                # V√≤ng quay ph·∫£i thu
    X13 = div(365.0, turnover) if pd.notna(turnover) and turnover != 0 else np.nan  # K·ª≥ thu ti·ªÅn BQ
    X14 = div(DTT_cur, TTS_avg)                      # Hi·ªáu su·∫•t s·ª≠ d·ª•ng t√†i s·∫£n

    ratios = pd.DataFrame([[X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14]],
                          columns=[f"X_{i}" for i in range(1, 15)])
    return ratios

# =========================
# UI & TRAIN MODEL
# =========================

# --- LOGIC CSS V√Ä LOGO (Y√äU C·∫¶U 2 & 3) ---

# Th√™m logo v√† thi·∫øt l·∫≠p CSS cho giao di·ªán ƒë·ªè b·ªçc ƒë√¥ (Bordeaux)
AGRIBANK_LOGO_URL = "https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Agribank_logo.svg/1024px-Agribank_logo.svg.png" # URL logo chu·∫©n
BORDEAUX_RED = "#800000" # M√£ m√†u ƒë·ªè b·ªçc ƒë√¥

st.markdown(
    f"""
    <style>
        /* 3. Logo Agribank */
        [data-testid="stSidebar"] {{
            padding-top: 50px; /* T·∫°o kho·∫£ng tr·ªëng cho logo */
        }}
        .logo-img {{
            position: fixed;
            top: 10px;
            left: 20px;
            width: 100px; /* K√≠ch th∆∞·ªõc logo */
            height: auto;
            z-index: 1000;
        }}
        
        /* 2. Ph·ªëi m√†u N·ªÅn Tr·∫Øng - ƒê·ªè Bordeaux */
        /* M√†u ch·ªØ ti√™u ƒë·ªÅ Streamlit */
        .st-emotion-cache-1wivap2 {{ /* Streamlit Title */
            color: {BORDEAUX_RED} !important;
        }}
        /* M√†u n·ªÅn Sidebar v√† Header: Gi·ªØ nguy√™n (Streamlit Default/Theming) ho·∫∑c c√≥ th·ªÉ ƒë·ªïi */
        /* ƒê·ªïi m√†u ti√™u ƒë·ªÅ h2 v√† h3 sang ƒê·ªè Bordeaux */
        h1, h2, h3, h4, h5, h6 {{
            color: {BORDEAUX_RED} !important;
        }}
        /* ƒê·ªïi m√†u n√∫t b·∫•m sang ƒê·ªè Bordeaux */
        div.stButton > button:first-child {{
            background-color: {BORDEAUX_RED};
            color: white;
            border-radius: 5px;
            border-color: {BORDEAUX_RED};
        }}
        div.stButton > button:hover {{
            background-color: #660000; /* M√†u ƒë·∫≠m h∆°n khi hover */
            color: white;
            border-color: #660000;
        }}
    </style>
    <img src="{AGRIBANK_LOGO_URL}" class="logo-img">
    """,
    unsafe_allow_html=True
)
# END OF LOGIC CSS


np.random.seed(0)
st.title("D·ª∞ B√ÅO THAM S·ªê PD")
# 1. ·∫®N PH·∫¶N D·ª∞ B√ÅO V·ª† N·ª¢/T·∫¢I CSV BAN ƒê·∫¶U
# st.write("## D·ª± b√°o x√°c su·∫•t v·ª° n·ª£ c·ªßa kh√°ch h√†ng_PD") # ·∫®N
# --- Ph·∫ßn t·∫£i CSV Hu·∫•n luy·ªán c≈©ng s·∫Ω ƒë∆∞·ª£c ·∫©n n·∫øu ng∆∞·ªùi d√πng ch·ªçn m·ª•c d·ª± b√°o

# Hi·ªÉn th·ªã tr·∫°ng th√°i th∆∞ vi·ªán AI
st.caption("üîé Tr·∫°ng th√°i Gemini: " + ("‚úÖ s·∫µn s√†ng (c·∫ßn 'GEMINI_API_KEY' trong Secrets)" if _GEMINI_OK else "‚ö†Ô∏è Thi·∫øu th∆∞ vi·ªán google-genai."))

# --- Logic t·∫£i file CSV Hu·∫•n luy·ªán (Ch·ªâ hi·ªán khi ch∆∞a ch·ªçn m·ª•c d·ª± b√°o) ---
df = None
menu = ["M·ª•c ti√™u c·ªßa m√¥ h√¨nh", "X√¢y d·ª±ng m√¥ h√¨nh", "S·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ d·ª± b√°o"]
choice = st.sidebar.selectbox('Danh m·ª•c t√≠nh nƒÉng', menu)

if choice != 'S·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ d·ª± b√°o':
    # Hi·ªÉn th·ªã ph·∫ßn hu·∫•n luy·ªán ch·ªâ khi KH√îNG ch·ªçn m·ª•c d·ª± b√°o
    st.write("## 1. Hu·∫•n luy·ªán M√¥ h√¨nh PD")
    st.markdown("**(Ph·∫ßn n√†y d√πng ƒë·ªÉ t·∫£i d·ªØ li·ªáu v√† hu·∫•n luy·ªán m√¥ h√¨nh)**")
    
    try:
        df = pd.read_csv('DATASET.csv', encoding='latin-1')
    except Exception:
        df = None

    uploaded_file = st.file_uploader("T·∫£i CSV d·ªØ li·ªáu hu·∫•n luy·ªán", type=['csv'])
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file, encoding='latin-1')

    if df is None:
        st.info("H√£y t·∫£i file CSV hu·∫•n luy·ªán (c√≥ c·ªôt 'default' v√† X_1...X_14).")
        st.stop()

# --- Ti·∫øp t·ª•c logic hu·∫•n luy·ªán/ki·ªÉm tra n·∫øu c√≥ df ---
if df is not None:
    # Ki·ªÉm tra c·ªôt c·∫ßn thi·∫øt
    required_cols = ['default'] + [f"X_{i}" for i in range(1, 15)]
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        st.error(f"Thi·∫øu c·ªôt: {missing}")
        st.stop()
    
    # Train model
    X = df.drop(columns=['default'])
    y = df['default'].astype(int)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    model = LogisticRegression(random_state=42, max_iter=1000, class_weight="balanced", solver="lbfgs")
    model.fit(X_train, y_train)

    # D·ª± b√°o & ƒë√°nh gi√° (Gi·ªØ l·∫°i ƒë·ªÉ c√°c b∆∞·ªõc sau d√πng)
    y_pred_in = model.predict(X_train)
    y_proba_in = model.predict_proba(X_train)[:, 1]
    y_pred_out = model.predict(X_test)
    y_proba_out = model.predict_proba(X_test)[:, 1]

    metrics_in = {
        "accuracy_in": accuracy_score(y_train, y_pred_in),
        "precision_in": precision_score(y_train, y_pred_in, zero_division=0),
        "recall_in": recall_score(y_train, y_pred_in, zero_division=0),
        "f1_in": f1_score(y_train, y_pred_in, zero_division=0),
        "auc_in": roc_auc_score(y_train, y_proba_in),
    }
    metrics_out = {
        "accuracy_out": accuracy_score(y_test, y_pred_out),
        "precision_out": precision_score(y_test, y_pred_out, zero_division=0),
        "recall_out": recall_score(y_test, y_pred_out, zero_division=0),
        "f1_out": f1_score(y_test, y_pred_out, zero_division=0),
        "auc_out": roc_auc_score(y_test, y_proba_out),
    }

# --- END Logic t·∫£i/hu·∫•n luy·ªán ---


if choice == 'M·ª•c ti√™u c·ªßa m√¥ h√¨nh':    
    st.subheader("M·ª•c ti√™u c·ªßa m√¥ h√¨nh")
    st.markdown("**D·ª± b√°o x√°c su·∫•t v·ª° n·ª£ (PD) c·ªßa kh√°ch h√†ng doanh nghi·ªáp** d·ª±a tr√™n b·ªô ch·ªâ s·ªë X1‚ÄìX14.")
    # ·∫£nh minh h·ªça (c√≥ th·ªÉ kh√¥ng t·ªìn t·∫°i)
    for img in ["hinh2.jpg", "LogReg_1.png", "hinh3.png"]:
        try:
            st.image(img)
        except Exception:
            st.warning(f"Kh√¥ng t√¨m th·∫•y {img}")

elif choice == 'X√¢y d·ª±ng m√¥ h√¨nh':
    st.subheader("X√¢y d·ª±ng m√¥ h√¨nh")
    
    if df is None:
        st.warning("Vui l√≤ng t·∫£i file CSV Hu·∫•n luy·ªán ·ªü m·ª•c 1 tr∆∞·ªõc.")
        st.stop()

    st.write("##### 1) Hi·ªÉn th·ªã d·ªØ li·ªáu")
    st.dataframe(df.head(3))
    st.dataframe(df.tail(3))  

    st.write("##### 2) Tr·ª±c quan h√≥a d·ªØ li·ªáu")
    col = st.text_input('Nh·∫≠p t√™n bi·∫øn X mu·ªën v·∫Ω', value='X_1')
    if col in df.columns:
        try:
            fig, ax = plt.subplots(figsize=(8, 5))
            sns.scatterplot(data=df, x=col, y='default', alpha=0.4, ax=ax)
            # V·∫Ω ƒë∆∞·ªùng logistic regression theo 1 bi·∫øn
            x_range = np.linspace(df[col].min(), df[col].max(), 100)
            X_temp = df[[col]].copy()
            y_temp = df['default']
            lr_temp = LogisticRegression(max_iter=1000)
            lr_temp.fit(X_temp, y_temp)
            x_test = pd.DataFrame({col: x_range})
            y_curve = lr_temp.predict_proba(x_test)[:, 1]
            ax.plot(x_range, y_curve, color='red', linewidth=2)
            ax.set_ylabel('X√°c su·∫•t default')
            ax.set_xlabel(col)
            st.pyplot(fig)
            plt.close()
        except Exception as e:
            st.error(f"L·ªói khi v·∫Ω bi·ªÉu ƒë·ªì: {e}")
    else:
        st.warning("Bi·∫øn kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu.")

    st.write("##### 3) K·∫øt qu·∫£ ƒë√°nh gi√°")
    dt = pd.DataFrame([metrics_in | metrics_out])
    st.dataframe(dt)

    st.write("##### 4) Ma tr·∫≠n nh·∫ßm l·∫´n (test)")
    cm = confusion_matrix(y_test, y_pred_out)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    fig2, ax = plt.subplots()
    disp.plot(ax=ax)
    st.pyplot(fig2)
    plt.close()

elif choice == 'S·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ d·ª± b√°o':
    st.subheader("S·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ d·ª± b√°o & ph√¢n t√≠ch AI (3 sheet)")
    st.caption("File ph·∫£i c√≥ ƒë·ªß 3 sheet: **CDKT ; BCTN ; LCTT**")

    up_xlsx = st.file_uploader("T·∫£i **ho_so_dn.xlsx**", type=["xlsx"], key="ho_so_dn")
    if up_xlsx is not None:
        # T√≠nh X1..X14 t·ª´ 3 sheet
        try:
            ratios_df = compute_ratios_from_three_sheets(up_xlsx)
        except Exception as e:
            st.error(f"L·ªói t√≠nh X1‚Ä¶X14: {e}")
            st.stop()

        st.markdown("### K·∫øt qu·∫£ t√≠nh X1‚Ä¶X14")
        st.dataframe(ratios_df.style.format("{:.4f}"))
        
        # T·∫°o payload data cho AI
        data_for_ai = ratios_df.iloc[0].to_dict()

        # (Tu·ª≥ ch·ªçn) d·ª± b√°o PD n·∫øu m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán ƒë√∫ng c·∫•u tr√∫c X_1..X_14
        if 'model' in locals(): # Ch·ªâ d·ª± b√°o n·∫øu m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c train th√†nh c√¥ng
            if set(X.columns) == set(ratios_df.columns):
                with st.expander("X√°c su·∫•t v·ª° n·ª£ d·ª± b√°o (PD)"):
                    try:
                        probs = model.predict_proba(ratios_df[X.columns])[:, 1]
                        preds = (probs >= 0.5).astype(int)
                        show = ratios_df.copy()
                        show["pd"] = probs
                        show["pred_default"] = preds
                        st.dataframe(show.style.format({"pd": "{:.3f}"}))
                        # Th√™m PD v√†o payload cho AI
                        data_for_ai['PD_Probability'] = probs[0]
                        data_for_ai['PD_Prediction'] = "Default (V·ª° n·ª£)" if preds[0] == 1 else "Non-Default (Kh√¥ng v·ª° n·ª£)"
                    except Exception as e:
                        st.warning(f"Kh√¥ng d·ª± b√°o ƒë∆∞·ª£c PD: {e}")
            else:
                st.warning("C·∫•u tr√∫c file d·ªØ li·ªáu Hu·∫•n luy·ªán kh√¥ng kh·ªõp v·ªõi c·∫•u tr√∫c ch·ªâ s·ªë X1-X14.")
        else:
            st.warning("M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. Vui l√≤ng quay l·∫°i m·ª•c 'X√¢y d·ª±ng m√¥ h√¨nh' ƒë·ªÉ t·∫£i d·ªØ li·ªáu v√† hu·∫•n luy·ªán.")
            
        # Gemini Ph√¢n t√≠ch & khuy·∫øn ngh·ªã
        st.markdown("### Ph√¢n t√≠ch AI & ƒë·ªÅ xu·∫•t CHO VAY/KH√îNG CHO VAY")

        if st.button("Y√™u c·∫ßu AI Ph√¢n t√≠ch"):
            api_key = st.secrets.get("GEMINI_API_KEY")
            
            if api_key:
                with st.spinner('ƒêang g·ª≠i d·ªØ li·ªáu v√† ch·ªù Gemini ph√¢n t√≠ch...'):
                    ai_result = get_ai_analysis(data_for_ai, api_key)
                    st.markdown("**K·∫øt qu·∫£ Ph√¢n t√≠ch t·ª´ Gemini AI:**")
                    st.info(ai_result)
            else:
                st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API. Vui l√≤ng c·∫•u h√¨nh Kh√≥a **'GEMINI_API_KEY'** trong Streamlit Secrets.")

    else:
        st.info("H√£y t·∫£i **ho_so_dn.xlsx** (ƒë·ªß 3 sheet) ƒë·ªÉ t√≠nh X1‚Ä¶X14, d·ª± b√°o PD v√† ph√¢n t√≠ch AI.")
