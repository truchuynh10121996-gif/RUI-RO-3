# ED.py ‚Äî Streamlit PD + Ph√¢n t√≠ch Gemini (Phi√™n b·∫£n Chuy√™n nghi·ªáp)

# =========================
# TH∆Ø VI·ªÜN B·∫ÆT BU·ªòC V√Ä B·ªî SUNG
# =========================
from datetime import datetime
import os
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
# Th∆∞ vi·ªán Machine Learning v√† M√¥ h√¨nh
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    confusion_matrix,
    f1_score,
    accuracy_score,
    recall_score,
    precision_score,
    roc_auc_score,
    ConfusionMatrixDisplay,
)

# =========================
# TH√äM TH∆Ø VI VI·ªÜN GOOGLE GEMINI
# =========================
try:
    from google import genai
    from google.genai.errors import APIError
    _GEMINI_OK = True
except Exception:
    genai = None
    APIError = Exception
    _GEMINI_OK = False

# Gi·ªØ l·∫°i logic OpenAI (n·∫øu c√≥) nh∆∞ng kh√¥ng d√πng
try:
    from openai import OpenAI
    _OPENAI_OK = True
except Exception:
    OpenAI = None
    _OPENAI_OK = False


MODEL_NAME = "gemini-2.5-flash" 

# =========================
# H√ÄM G·ªåI GEMINI API
# =========================

def get_ai_analysis(data_payload: dict, api_key: str) -> str:
    """
    S·ª≠ d·ª•ng Gemini API ƒë·ªÉ ph√¢n t√≠ch ch·ªâ s·ªë t√†i ch√≠nh.
    """
    if not _GEMINI_OK:
        return "L·ªói: Thi·∫øu th∆∞ vi·ªán google-genai (c·∫ßn c√†i ƒë·∫∑t: pip install google-genai)."

    client = genai.Client(api_key=api_key)

    sys_prompt = (
        "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch t√≠n d·ª•ng doanh nghi·ªáp t·∫°i ng√¢n h√†ng. "
        "Ph√¢n t√≠ch to√†n di·ªán d·ª±a tr√™n 14 ch·ªâ s·ªë t√†i ch√≠nh (X1..X14). "
        "N√™u r√µ: (1) Kh·∫£ nƒÉng sinh l·ªùi, (2) Thanh kho·∫£n, (3) C∆° c·∫•u n·ª£, (4) Hi·ªáu qu·∫£ ho·∫°t ƒë·ªông. "
        "K·∫øt th√∫c b·∫±ng khuy·∫øn ngh·ªã in hoa: CHO VAY ho·∫∑c KH√îNG CHO VAY, k√®m 2‚Äì3 ƒëi·ªÅu ki·ªán n·∫øu CHO VAY. "
        "Vi·∫øt b·∫±ng ti·∫øng Vi·ªát s√∫c t√≠ch, chuy√™n nghi·ªáp."
    )
    
    user_prompt = "B·ªô ch·ªâ s·ªë X1..X14 c·∫ßn ph√¢n t√≠ch:\n" + str(data_payload) + "\n\nH√£y ph√¢n t√≠ch v√† ƒë∆∞a ra khuy·∫øn ngh·ªã."

    try:
        response = client.models.generate_content(
            model=MODEL_NAME,
            contents=[
                 {"role": "user", "parts": [{"text": sys_prompt + "\n\n" + user_prompt}]}
            ],
            config={"system_instruction": sys_prompt}
        )
        return response.text
    except APIError as e:
        return f"L·ªói g·ªçi API Gemini: {e}"
    except Exception as e:
        return f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"


# =========================
# T√çNH X1..X14 T·ª™ 3 SHEET (CDKT/BCTN/LCTT)
# =========================

# Alias c√°c d√≤ng quan tr·ªçng trong t·ª´ng sheet
ALIAS_IS = {
    "doanh_thu_thuan": ["Doanh thu thu·∫ßn", "Doanh thu b√°n h√†ng", "Doanh thu thu·∫ßn v·ªÅ b√°n h√†ng v√† cung c·∫•p d·ªãch v·ª•"],
    "gia_von": ["Gi√° v·ªën h√†ng b√°n"],
    "loi_nhuan_gop": ["L·ª£i nhu·∫≠n g·ªôp"],
    "chi_phi_lai_vay": ["Chi ph√≠ l√£i vay", "Chi ph√≠ t√†i ch√≠nh (trong ƒë√≥: chi ph√≠ l√£i vay)"],
    "loi_nhuan_truoc_thue": ["T·ªïng l·ª£i nhu·∫≠n k·∫ø to√°n tr∆∞·ªõc thu·∫ø", "L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø", "L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø thu nh·∫≠p DN"],
}
ALIAS_BS = {
    "tong_tai_san": ["T·ªïng t√†i s·∫£n"],
    "von_chu_so_huu": ["V·ªën ch·ªß s·ªü h·ªØu", "V·ªën CSH"],
    "no_phai_tra": ["N·ª£ ph·∫£i tr·∫£"],
    "tai_san_ngan_han": ["T√†i s·∫£n ng·∫Øn h·∫°n"],
    "no_ngan_han": ["N·ª£ ng·∫Øn h·∫°n"],
    "hang_ton_kho": ["H√†ng t·ªìn kho"],
    "tien_tdt": ["Ti·ªÅn v√† c√°c kho·∫£n t∆∞∆°ng ƒë∆∞∆°ng ti·ªÅn", "Ti·ªÅn v√† t∆∞∆°ng ƒë∆∞∆°ng ti·ªÅn"],
    "phai_thu_kh": ["Ph·∫£i thu ng·∫Øn h·∫°n c·ªßa kh√°ch h√†ng", "Ph·∫£i thu kh√°ch h√†ng"],
    "no_dai_han_den_han": ["N·ª£ d√†i h·∫°n ƒë·∫øn h·∫°n tr·∫£", "N·ª£ d√†i h·∫°n ƒë·∫øn h·∫°n"],
}
ALIAS_CF = {
    "khau_hao": ["Kh·∫•u hao TSCƒê", "Kh·∫•u hao", "Chi ph√≠ kh·∫•u hao"],
}

def _pick_year_cols(df: pd.DataFrame):
    """Ch·ªçn 2 c·ªôt nƒÉm g·∫ßn nh·∫•t t·ª´ sheet (∆∞u ti√™n c·ªôt c√≥ nh√£n l√† nƒÉm)."""
    numeric_years = []
    for c in df.columns[1:]:
        try:
            y = int(float(str(c).strip()))
            if 1990 <= y <= 2100:
                numeric_years.append((y, c))
        except Exception:
            continue
    if numeric_years:
        numeric_years.sort(key=lambda x: x[0])
        if len(numeric_years) >= 2:
            return numeric_years[-2][1], numeric_years[-1][1]
        elif len(numeric_years) == 1:
            # N·∫øu ch·ªâ c√≥ 1 nƒÉm, d√πng c·ªôt cu·ªëi c√πng l√†m c·ªôt hi·ªán t·∫°i, c·ªôt tr∆∞·ªõc l√† c·ªôt cu·ªëi c√πng th·ª© 2
            cols = df.columns[-2:]
            return cols[0], numeric_years[0][1] # Gi·∫£ ƒë·ªãnh c·ªôt tr∆∞·ªõc nƒÉm ƒë√≥ l√† c·ªôt cu·ªëi c√πng th·ª© 2
    # fallback: 2 c·ªôt cu·ªëi
    cols = df.columns[-2:]
    return cols[0], cols[1]

def _get_row_vals(df: pd.DataFrame, aliases: list[str]):
    """T√¨m d√≤ng theo alias (contains, kh√¥ng ph√¢n bi·ªát hoa/th∆∞·ªùng). Tr·∫£ v·ªÅ (prev, cur) theo 2 c·ªôt nƒÉm g·∫ßn nh·∫•t."""
    if df.empty:
        return np.nan, np.nan
        
    label_col = df.columns[0]
    
    # ƒê·∫£m b·∫£o c√≥ √≠t nh·∫•t 2 c·ªôt ngo√†i c·ªôt label
    if len(df.columns) < 3:
        return np.nan, np.nan
        
    prev_col, cur_col = _pick_year_cols(df)
    
    mask = False
    for alias in aliases:
        mask = mask | df[label_col].astype(str).str.contains(alias, case=False, na=False)
    rows = df[mask]
    
    if rows.empty:
        return np.nan, np.nan
        
    row = rows.iloc[0]

    def to_num(x):
        try:
            return float(str(x).replace(",", "").replace(" ", ""))
        except Exception:
            return np.nan

    return to_num(row.get(prev_col, np.nan)), to_num(row.get(cur_col, np.nan))

def compute_ratios_from_three_sheets(xlsx_file) -> pd.DataFrame:
    """ƒê·ªçc 3 sheet CDKT/BCTN/LCTT v√† t√≠nh X1..X14 theo y√™u c·∫ßu."""
    # ƒê·ªçc 3 sheet; c·∫ßn openpyxl trong requirements
    try:
        bs = pd.read_excel(xlsx_file, sheet_name="CDKT", engine="openpyxl")
        is_ = pd.read_excel(xlsx_file, sheet_name="BCTN", engine="openpyxl")
        cf = pd.read_excel(xlsx_file, sheet_name="LCTT", engine="openpyxl")
    except ValueError as e:
        # B·∫Øt l·ªói n·∫øu thi·∫øu sheet
        raise ValueError(f"L·ªói: File Excel thi·∫øu m·ªôt trong ba sheet b·∫Øt bu·ªôc (CDKT, BCTN, LCTT). Chi ti·∫øt: {e}")
    except Exception as e:
        raise Exception(f"L·ªói khi ƒë·ªçc file Excel: {e}")

    # ---- KQKD (BCTN)
    DTT_prev, DTT_cur    = _get_row_vals(is_, ALIAS_IS["doanh_thu_thuan"])
    GVHB_prev, GVHB_cur = _get_row_vals(is_, ALIAS_IS["gia_von"])
    LNG_prev, LNG_cur    = _get_row_vals(is_, ALIAS_IS["loi_nhuan_gop"])
    LNTT_prev, LNTT_cur = _get_row_vals(is_, ALIAS_IS["loi_nhuan_truoc_thue"])
    LV_prev, LV_cur      = _get_row_vals(is_, ALIAS_IS["chi_phi_lai_vay"])

    # ---- CƒêKT (CDKT)
    TTS_prev, TTS_cur      = _get_row_vals(bs, ALIAS_BS["tong_tai_san"])
    VCSH_prev, VCSH_cur    = _get_row_vals(bs, ALIAS_BS["von_chu_so_huu"])
    NPT_prev, NPT_cur      = _get_row_vals(bs, ALIAS_BS["no_phai_tra"])
    TSNH_prev, TSNH_cur    = _get_row_vals(bs, ALIAS_BS["tai_san_ngan_han"])
    NNH_prev, NNH_cur      = _get_row_vals(bs, ALIAS_BS["no_ngan_han"])
    HTK_prev, HTK_cur      = _get_row_vals(bs, ALIAS_BS["hang_ton_kho"])
    Tien_prev, Tien_cur    = _get_row_vals(bs, ALIAS_BS["tien_tdt"])
    KPT_prev, KPT_cur      = _get_row_vals(bs, ALIAS_BS["phai_thu_kh"])
    NDH_prev, NDH_cur      = _get_row_vals(bs, ALIAS_BS["no_dai_han_den_han"])

    # ---- LCTT (LCTT) ‚Äì l·∫•y Kh·∫•u hao n·∫øu c√≥
    KH_prev, KH_cur = _get_row_vals(cf, ALIAS_CF["khau_hao"])

    # Chu·∫©n ho√° s·ªë √¢m th∆∞·ªùng th·∫•y ·ªü GVHB, chi ph√≠ l√£i vay, kh·∫•u hao
    if pd.notna(GVHB_cur): GVHB_cur = abs(GVHB_cur)
    if pd.notna(LV_cur):   LV_cur   = abs(LV_cur)
    if pd.notna(KH_cur):   KH_cur   = abs(KH_cur)

    # Trung b√¨nh ƒë·∫ßu/cu·ªëi k·ª≥
    def avg(a, b):
        if pd.isna(a) and pd.isna(b): return np.nan
        if pd.isna(a): return b
        if pd.isna(b): return a
        return (a + b) / 2.0
    TTS_avg  = avg(TTS_cur,  TTS_prev)
    VCSH_avg = avg(VCSH_cur, VCSH_prev)
    HTK_avg  = avg(HTK_cur,  HTK_prev)
    KPT_avg  = avg(KPT_cur,  KPT_prev)

    # EBIT ~ LNTT + chi ph√≠ l√£i vay (n·∫øu thi·∫øu EBIT ri√™ng)
    EBIT_cur = (LNTT_cur + LV_cur) if (pd.notna(LNTT_cur) and pd.notna(LV_cur)) else np.nan
    # N·ª£ d√†i h·∫°n ƒë·∫øn h·∫°n tr·∫£: c√≥ file kh√¥ng ghi -> set 0
    NDH_cur = 0.0 if pd.isna(NDH_cur) else NDH_cur

    def div(a, b):
        return np.nan if (b is None or pd.isna(b) or b == 0) else a / b

    # ==== T√çNH X1..X14 ====
    X1  = div(LNG_cur, DTT_cur)                         # Bi√™n LN g·ªôp
    X2  = div(LNTT_cur, DTT_cur)                        # Bi√™n LNTT
    X3  = div(LNTT_cur, TTS_avg)                        # ROA (tr∆∞·ªõc thu·∫ø)
    X4  = div(LNTT_cur, VCSH_avg)                       # ROE (tr∆∞·ªõc thu·∫ø)
    X5  = div(NPT_cur,  TTS_cur)                        # N·ª£/T√†i s·∫£n
    X6  = div(NPT_cur,  VCSH_cur)                       # N·ª£/VCSH
    X7  = div(TSNH_cur, NNH_cur)                        # Thanh to√°n hi·ªán h√†nh
    X8  = div((TSNH_cur - HTK_cur) if pd.notna(TSNH_cur) and pd.notna(HTK_cur) else np.nan, NNH_cur)  # Thanh to√°n nhanh
    X9  = div(EBIT_cur, LV_cur)                         # Kh·∫£ nƒÉng tr·∫£ l√£i
    X10 = div((EBIT_cur + (KH_cur if pd.notna(KH_cur) else 0.0)),
                 (LV_cur + NDH_cur) if pd.notna(LV_cur) else np.nan)  # Kh·∫£ nƒÉng tr·∫£ n·ª£ g·ªëc
    X11 = div(Tien_cur, VCSH_cur)                       # Ti·ªÅn/VCSH
    X12 = div(GVHB_cur, HTK_avg)                        # V√≤ng quay HTK
    turnover = div(DTT_cur, KPT_avg)                    # V√≤ng quay ph·∫£i thu
    X13 = div(365.0, turnover) if pd.notna(turnover) and turnover != 0 else np.nan  # K·ª≥ thu ti·ªÅn BQ
    X14 = div(DTT_cur, TTS_avg)                         # Hi·ªáu su·∫•t s·ª≠ d·ª•ng t√†i s·∫£n

    ratios = pd.DataFrame([[X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14]],
                         columns=[f"X_{i}" for i in range(1, 15)])
    return ratios

# =========================
# UI & TRAIN MODEL (PH·∫¶N N√ÇNG C·∫§P GIAO DI·ªÜN)
# =========================

# 1. C·∫•u h√¨nh Trang v√† CSS T√πy ch·ªânh
st.set_page_config(
    page_title="H·ªá th·ªëng Ph√¢n t√≠ch & D·ª± b√°o PD Doanh nghi·ªáp",
    page_icon="üè¶",
    layout="wide", # S·ª≠ d·ª•ng to√†n b·ªô chi·ªÅu r·ªông m√†n h√¨nh
    initial_sidebar_state="expanded"
)

# Th√™m CSS t√πy ch·ªânh ƒë·ªÉ t·ªëi ∆∞u h√≥a Tabs v√† Metrics
st.markdown("""
<style>
/* ƒê·∫£m b·∫£o tab tr√¥ng hi·ªán ƒë·∫°i h∆°n */
.stTabs [data-baseweb="tab-list"] {
    gap: 24px;
}
.stTabs [data-baseweb="tab"] {
    height: 50px;
    font-size: 18px;
    font-weight: bold;
}
.stTabs [aria-selected="true"] {
    border-bottom: 4px solid #007bff; /* M√†u xanh chuy√™n nghi·ªáp */
    color: #007bff;
}
/* Thi·∫øt k·∫ø Metric r√µ r√†ng, nh·∫•n m·∫°nh s·ªë li·ªáu */
.stMetric > div:nth-child(2) > div:nth-child(1) {
    font-size: 2.5rem; 
    font-weight: 700;
}
</style>
""", unsafe_allow_html=True)

np.random.seed(0)

st.title("üè¶ PH√ÇN T√çCH V√Ä D·ª∞ B√ÅO PD DOANH NGHI·ªÜP")
st.markdown("""
<div style="padding: 10px 0 20px 0;">
    <span style="font-size: 1.1em; color: #555;">C√¥ng c·ª• d·ª± b√°o X√°c su·∫•t V·ª° n·ª£ (PD) d·ª±a tr√™n ch·ªâ s·ªë t√†i ch√≠nh v√† ph√¢n t√≠ch chuy√™n s√¢u b·ªüi Gemini AI.</span>
</div>
""", unsafe_allow_html=True)
st.divider()

# 2. X·ª≠ l√Ω D·ªØ li·ªáu ·ªü Sidebar v√† Giai ƒëo·∫°n Hu·∫•n luy·ªán

# ƒê∆∞a ph·∫ßn t·∫£i d·ªØ li·ªáu hu·∫•n luy·ªán v√†o Sidebar
st.sidebar.header("‚öôÔ∏è C·∫•u h√¨nh D·ªØ li·ªáu Hu·∫•n luy·ªán")
uploaded_file = st.sidebar.file_uploader(
    "1. T·∫£i CSV D·ªØ li·ªáu Hu·∫•n luy·ªán", 
    type=['csv'], 
    help="File CSV ph·∫£i c√≥ c·ªôt 'default' (m·ª•c ti√™u) v√† X_1...X_14"
)
try:
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file, encoding='latin-1')
    elif os.path.exists('DATASET.csv'): # Gi·ªØ l·∫°i c∆° ch·∫ø t·∫£i file default n·∫øu c√≥
        df = pd.read_csv('DATASET.csv', encoding='latin-1')
    else:
        df = None
except Exception:
    df = None

# Hi·ªÉn th·ªã tr·∫°ng th√°i AI trong Sidebar
st.sidebar.markdown("---")
st.sidebar.caption("üîé Tr·∫°ng th√°i AI: " + ("‚úÖ Gemini s·∫µn s√†ng" if _GEMINI_OK else "‚ö†Ô∏è Thi·∫øu th∆∞ vi·ªán google-genai."))
st.sidebar.info("Vui l√≤ng c·∫•u h√¨nh Kh√≥a **'GEMINI_API_KEY'** trong Streamlit Secrets ƒë·ªÉ s·ª≠ d·ª•ng ch·ª©c nƒÉng AI.")

if df is None:
    st.info("‚ö†Ô∏è M√¥ h√¨nh PD ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. Vui l√≤ng t·∫£i file CSV hu·∫•n luy·ªán ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    st.stop()

# Ki·ªÉm tra c·ªôt c·∫ßn thi·∫øt
required_cols = ['default'] + [f"X_{i}" for i in range(1, 15)]
missing = [c for c in required_cols if c not in df.columns]
if missing:
    st.error(f"D·ªØ li·ªáu hu·∫•n luy·ªán b·ªã thi·∫øu c·ªôt: {missing}")
    st.stop()

# Hu·∫•n luy·ªán m√¥ h√¨nh (Logic gi·ªØ nguy√™n)
X = df.drop(columns=['default'])
y = df['default'].astype(int)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
model = LogisticRegression(random_state=42, max_iter=1000, class_weight="balanced", solver="lbfgs")
model.fit(X_train, y_train)

# T√≠nh Metrics (Logic gi·ªØ nguy√™n)
y_pred_in = model.predict(X_train)
y_proba_in = model.predict_proba(X_train)[:, 1]
y_pred_out = model.predict(X_test)
y_proba_out = model.predict_proba(X_test)[:, 1]

metrics_in = {
   "accuracy_in": accuracy_score(y_train, y_pred_in), "precision_in": precision_score(y_train, y_pred_in, zero_division=0),
   "recall_in": recall_score(y_train, y_pred_in, zero_division=0), "f1_in": f1_score(y_train, y_pred_in, zero_division=0),
   "auc_in": roc_auc_score(y_train, y_proba_in),
}
metrics_out = {
   "accuracy_out": accuracy_score(y_test, y_pred_out), "precision_out": precision_score(y_test, y_pred_out, zero_division=0),
   "recall_out": recall_score(y_test, y_pred_out, zero_division=0), "f1_out": f1_score(y_test, y_pred_out, zero_division=0),
   "auc_out": roc_auc_score(y_test, y_proba_out),
}


# 3. S·ª≠ d·ª•ng Tab Navigation (thay th·∫ø cho st.sidebar.selectbox)
tab1, tab2, tab3 = st.tabs(["üí° T·ªïng quan Dashboard", "üî¨ ƒê√°nh gi√° M√¥ h√¨nh PD", "üîé D·ª± b√°o & Ph√¢n t√≠ch AI"])


# --- TAB 1: T·ªïng quan Dashboard ---
with tab1:
    st.header("T√≥m t·∫Øt Hi·ªáu su·∫•t M√¥ h√¨nh")
    st.markdown("D·ª± b√°o **X√°c su·∫•t V·ª° n·ª£ (PD)** c·ªßa kh√°ch h√†ng doanh nghi·ªáp d·ª±a tr√™n b·ªô ch·ªâ s·ªë t√†i ch√≠nh (X1‚ÄìX14).")
    
    # Hi·ªÉn th·ªã Metric quan tr·ªçng b·∫±ng st.metric
    col_acc, col_auc, col_f1 = st.columns(3)
    
    with col_acc:
        st.metric(label="ƒê·ªô ch√≠nh x√°c (Test Set)", value=f"{metrics_out['accuracy_out']:.2%}", delta="T·ª∑ l·ªá d·ª± b√°o ƒë√∫ng")
    with col_auc:
        st.metric(label="AUC (Test Set)", value=f"{metrics_out['auc_out']:.3f}", delta=f"Train AUC: {metrics_in['auc_in']:.3f}")
    with col_f1:
        st.metric(label="F1 Score (Test Set)", value=f"{metrics_out['f1_out']:.2f}", delta="C√¢n b·∫±ng Precision/Recall")
    
    st.markdown("---")
    st.subheader("Ph√¢n ph·ªëi D·ªØ li·ªáu ƒê·∫ßu v√†o")
    st.dataframe(df[[f"X_{i}" for i in range(1, 15)]].describe().T.style.format("{:.3f}"))
    
    # ƒêo·∫°n code hi·ªÉn th·ªã ·∫£nh minh h·ªça c≈©
    # for img in ["hinh2.jpg", "LogReg_1.png", "hinh3.png"]:
    #     try:
    #         st.image(img)
    #     except Exception:
    #         pass # B·ªè qua l·ªói n·∫øu kh√¥ng t√¨m th·∫•y file

# --- TAB 2: X√¢y d·ª±ng M√¥ h√¨nh (Tr·ª±c quan h√≥a & ƒê√°nh gi√° chi ti·∫øt) ---
with tab2:
    st.header("Ph√¢n t√≠ch S√¢u M√¥ h√¨nh H·ªìi quy Logistic")
    
    st.subheader("1. Tr·ª±c quan h√≥a Bi·∫øn v√† ƒê∆∞·ªùng H·ªìi quy ƒê∆°n bi·∫øn")
    col_meta, col_vis = st.columns([1, 2])
    
    with col_meta:
        col = st.selectbox('Ch·ªçn Bi·∫øn X mu·ªën v·∫Ω', options=[f"X_{i}" for i in range(1, 15)], key='vis_var')
        st.markdown(f"**√ù nghƒ©a:** Ph√¢n t√≠ch quan h·ªá gi·ªØa **{col}** v√† x√°c su·∫•t Default.")
        
    with col_vis:
        if col in df.columns:
            try:
                fig, ax = plt.subplots(figsize=(8, 4))
                # Scatter plot data points
                sns.scatterplot(data=df, x=col, y='default', alpha=0.5, ax=ax, hue='default', palette={0: '#1f77b4', 1: '#d62728'}, legend=False)
                
                # V·∫Ω ƒë∆∞·ªùng logistic regression
                x_range = np.linspace(df[col].min(), df[col].max(), 100).reshape(-1, 1)
                lr_temp = LogisticRegression(max_iter=1000)
                lr_temp.fit(df[[col]], df['default'])
                y_curve = lr_temp.predict_proba(x_range)[:, 1]
                ax.plot(x_range, y_curve, color='black', linestyle='--', linewidth=2, label='ƒê∆∞·ªùng H·ªìi quy Log')
                
                ax.set_ylabel('X√°c su·∫•t Default')
                ax.set_xlabel(col)
                ax.grid(True, linestyle=':', alpha=0.6)
                st.pyplot(fig)
                plt.close()
            except Exception as e:
                st.error(f"L·ªói khi v·∫Ω bi·ªÉu ƒë·ªì: {e}")
    
    st.markdown("---")
    st.subheader("2. Ma tr·∫≠n Nh·∫ßm l·∫´n v√† Hi·ªáu su·∫•t Chi ti·∫øt")
    col_cm, col_metrics_detail = st.columns([1, 2])
    
    with col_cm:
        st.markdown("**Ma tr·∫≠n Nh·∫ßm l·∫´n (Test Set)**")
        cm = confusion_matrix(y_test, y_pred_out)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Default (0)', 'Default (1)'])
        fig2, ax = plt.subplots(figsize=(5, 5))
        disp.plot(ax=ax, cmap=plt.cm.Blues)
        st.pyplot(fig2)
        plt.close()
        
    with col_metrics_detail:
        st.markdown("**B·∫£ng so s√°nh Hi·ªáu su·∫•t (Train vs Test)**")
        dt_in = pd.Series(metrics_in).rename(lambda x: x.replace('_in', '')).to_frame('Train Set')
        dt_out = pd.Series(metrics_out).rename(lambda x: x.replace('_out', '')).to_frame('Test Set')
        dt = pd.concat([dt_in, dt_out], axis=1).T
        st.dataframe(dt.style.format("{:.4f}"))

# --- TAB 3: D·ª± b√°o & Ph√¢n t√≠ch AI ---
with tab3:
    st.header("Th·∫©m ƒë·ªãnh H·ªô s∆° T√≠n d·ª•ng v√† Khuy·∫øn ngh·ªã")
    
    st.caption("T·∫£i File Excel c·ªßa kh√°ch h√†ng (ch·ª©a 3 sheet: **CDKT ; BCTN ; LCTT**) ƒë·ªÉ t√≠nh to√°n X1-X14.")
    
    up_xlsx = st.file_uploader("T·∫£i **ho_so_dn.xlsx**", type=["xlsx"], key="ho_so_dn_analysis")
    
    if up_xlsx is not None:
        # T√≠nh X1..X14
        try:
            ratios_df = compute_ratios_from_three_sheets(up_xlsx)
        except Exception as e:
            st.error(f"L·ªói t√≠nh X1‚Ä¶X14. ƒê·∫£m b·∫£o file Excel c√≥ ƒë·ªß 3 sheet v√† ƒë√∫ng ƒë·ªãnh d·∫°ng: {e}")
            st.stop()

        st.markdown("### 1. Ch·ªâ s·ªë T√†i ch√≠nh X1‚Ä¶X14")
        st.dataframe(ratios_df.style.format("{:.4f}"))
        
        data_for_ai = ratios_df.iloc[0].to_dict()
        
        # D·ª± b√°o PD trong Container l√†m n·ªïi b·∫≠t
        with st.container(border=True):
            st.subheader("2. K·∫øt qu·∫£ D·ª± b√°o X√°c su·∫•t V·ª° n·ª£ (PD)")
            
            if set(X.columns) == set(ratios_df.columns):
                try:
                    probs = model.predict_proba(ratios_df[X.columns])[:, 1]
                    preds = (probs >= 0.5).astype(int)
                    
                    col_pd, col_pred = st.columns(2)
                    
                    # C·∫≠p nh·∫≠t payload cho Gemini
                    data_for_ai['PD_Probability'] = f"{probs[0]:.4f}"
                    status_text = "Default (V·ª° n·ª£)" if preds[0] == 1 else "Non-Default (Kh√¥ng v·ª° n·ª£)"
                    data_for_ai['PD_Prediction'] = status_text
                    
                    with col_pd:
                        st.metric(label="X√°c su·∫•t V·ª° n·ª£ (PD)", value=f"{probs[0]:.3f}", delta="Ng∆∞·ª°ng 0.5")
                    with col_pred:
                        if preds[0] == 1:
                            st.error(f"üö® R·ª¶I RO CAO: {status_text}", icon="üö®")
                        else:
                            st.success(f"‚úÖ R·ª¶I RO TH·∫§P: {status_text}", icon="‚úÖ")
                            
                except Exception as e:
                    st.warning(f"Kh√¥ng d·ª± b√°o ƒë∆∞·ª£c PD: L·ªói {e}")
            else:
                st.warning("M√¥ h√¨nh PD ch∆∞a s·∫µn s√†ng ho·∫∑c c·∫•u tr√∫c c·ªôt kh√¥ng kh·ªõp.")
                
        # Ph√¢n t√≠ch AI
        st.markdown("### 3. Khuy·∫øn ngh·ªã v√† Ph√¢n t√≠ch chuy√™n s√¢u t·ª´ Gemini AI")
        
        if st.button("‚ú® Y√™u c·∫ßu Gemini AI Ph√¢n t√≠ch T√≠n d·ª•ng", use_container_width=True, type="primary"):
            api_key = st.secrets.get("GEMINI_API_KEY")
            
            if api_key:
                with st.spinner('ƒêang g·ª≠i d·ªØ li·ªáu v√† ch·ªù Gemini ph√¢n t√≠ch...'):
                    ai_result = get_ai_analysis(data_for_ai, api_key)
                    
                    st.markdown("**K·∫øt qu·∫£ Ph√¢n t√≠ch t·ª´ Gemini AI:**")
                    # D·ª±a v√†o k·∫øt qu·∫£ ƒë·ªÉ d√πng m√†u s·∫Øc ph√π h·ª£p (Success/Error/Info)
                    if "KH√îNG CHO VAY" in ai_result.upper():
                        st.error(ai_result, icon="‚ùå")
                    elif "CHO VAY" in ai_result.upper():
                        st.success(ai_result, icon="üëç")
                    else:
                        st.info(ai_result)
            else:
                st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API. Vui l√≤ng c·∫•u h√¨nh Kh√≥a **'GEMINI_API_KEY'** trong Streamlit Secrets.")

    else:
        st.info("üí° H√£y t·∫£i **ho_so_dn.xlsx** (ƒë·ªß 3 sheet) ƒë·ªÉ t√≠nh X1‚Ä¶X14, d·ª± b√°o PD v√† ph√¢n t√≠ch AI.")
