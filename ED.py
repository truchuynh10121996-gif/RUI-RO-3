# app.py ‚Äî Streamlit PD + Ph√¢n t√≠ch Gemini
(C·∫¨P NH·∫¨T TH∆Ø VI·ªÜN)

# =========================
# TH∆Ø VI·ªÜN B·∫ÆT BU·ªòC V√Ä B·ªî SUNG
# (C·∫ßn ƒë·∫£m b·∫£o c√°c g√≥i n√†y ƒë∆∞·ª£c c√†i ƒë·∫∑t, v√≠
# d·ª• trong requirements.txt)
# =========================
from datetime import datetime
import os
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
# Th∆∞ vi·ªán Machine Learning v√† M√¥ h√¨nh
from sklearn.model_selection import
train_test_split
from sklearn.linear_model import
LogisticRegression
from sklearn.metrics import (
	confusion_matrix,
	f1_score,
	accuracy_score,
	recall_score,
	precision_score,
	roc_auc_score,
	ConfusionMatrixDisplay,
)
# C√°c th∆∞ vi·ªán B·ªî SUNG theo y√™u c·∫ßu (n·∫øu ƒë∆∞·ª£c
# s·ª≠ d·ª•ng trong code sau n√†y)
# import xgboost as xgb
# import graphviz
# import statsmodels.api as sm

# =========================
# TH√äM TH∆Ø VI·ªÜN GOOGLE GEMINI V√Ä OPENAI
# (CHO T∆Ø∆†NG TH√çCH V·ªöI REQ C≈®)
# =========================
try:
	from google import genai
	from google.genai.errors import APIError
	_GEMINI_OK = True
except Exception:
	genai = None
	APIError = Exception
	_GEMINI_OK = False

try:
	from openai import OpenAI
	_OPENAI_OK = True
except Exception:
	OpenAI = None
	_OPENAI_OK = False


MODEL_NAME = "gemini-2.5-flash" #
# Model m·∫°nh m·∫Ω v√† hi·ªáu qu·∫£ cho ph√¢n t√≠ch vƒÉn b·∫£n

# =========================
# H√ÄM G·ªåI GEMINI API
# =========================

def get_ai_analysis(data_payload: dict,
api_key: str) -> str:
	"""
	 S·ª≠
	 S·ª≠ d·ª•ng Gemini API ƒë·ªÉ ph√¢n t√≠ch ch·ªâ s·ªë t√†i ch√≠nh.
	"""
	if not _GEMINI_OK:
		# ƒê√£ s·ª≠a l·ªói: D√πng nh√°y ƒë∆°n b√™n ngo√†i ƒë·ªÉ bao chu·ªói c√≥ nh√°y ƒë∆°n b√™n trong
		return 'L·ªói: Thi·∫øu th∆∞ vi·ªán google-genai (c·∫ßn c√†i ƒë·∫∑t: pip install google-genai).'

	client = genai.Client(api_key=api_key)

	sys_prompt = (
		"B·∫°n l√† chuy√™n gia ph√¢n t√≠ch t√≠n d·ª•ng doanh nghi·ªáp t·∫°i ng√¢n h√†ng.
"
		"Ph√¢n t√≠ch to√†n di·ªán d·ª±a tr√™n 14 ch·ªâ s·ªë t√†i ch√≠nh (X1..X14). "
		"N√™u r√µ: (1) Kh·∫£ nƒÉng sinh l·ªùi, (2) Thanh kho·∫£n, (3) C∆° c·∫•u n·ª£, (4)
Hi·ªáu qu·∫£ ho·∫°t ƒë·ªông. "
		"K·∫øt th√∫c b·∫±ng khuy·∫øn ngh·ªã in hoa: CHO VAY ho·∫∑c KH√îNG CHO VAY, k√®m
2‚Äì3 ƒëi·ªÅu ki·ªán n·∫øu CHO VAY. "
		"Vi·∫øt b·∫±ng ti·∫øng Vi·ªát s√∫c t√≠ch, chuy√™n nghi·ªáp."
	 )
	 
	user_prompt = "B·ªô ch·ªâ s·ªë X1..X14 c·∫ßn ph√¢n t√≠ch:\n" +
str(data_payload) + "\n\nH√£y ph√¢n t√≠ch v√† ƒë∆∞a ra khuy·∫øn ngh·ªã."

	try:
		response = client.models.generate_content(
			model=MODEL_NAME,
			contents=[
				 {"role":
"user", "parts": [{"text": sys_prompt +
"\n\n" + user_prompt}]}
			],
			config={"system_instruction": sys_prompt}
		)
		return response.text
	except APIError as e:
		return f"L·ªói g·ªçi API Gemini: {e}"
	except Exception as e:
		return f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"


# =========================
# T√çNH X1..X14 T·ª™ 3 SHEET (CDKT/BCTN/LCTT)
# =========================

# Alias c√°c d√≤ng quan tr·ªçng trong t·ª´ng
# sheet
ALIAS_IS = {
	"doanh_thu_thuan": ["Doanh thu thu·∫ßn", "Doanh
thu b√°n h√†ng", "Doanh thu thu·∫ßn v·ªÅ b√°n h√†ng v√† cung c·∫•p d·ªãch v·ª•"],
	"gia_von": ["Gi√° v·ªën h√†ng b√°n"],
	"loi_nhuan_gop": ["L·ª£i nhu·∫≠n g·ªôp"],
	"chi_phi_lai_vay": ["Chi ph√≠ l√£i vay", "Chi ph√≠
t√†i ch√≠nh (trong ƒë√≥: chi ph√≠ l√£i vay)"],
	"loi_nhuan_truoc_thue": ["T·ªïng l·ª£i nhu·∫≠n k·∫ø to√°n tr∆∞·ªõc
thu·∫ø", "L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø", "L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø thu nh·∫≠p
DN"],
}
ALIAS_BS = {
	"tong_tai_san": ["T·ªïng t√†i s·∫£n"],
	"von_chu_so_huu": ["V·ªën ch·ªß s·ªü h·ªØu", "V·ªën
CSH"],
	"no_phai_tra": ["N·ª£ ph·∫£i tr·∫£"],
	"tai_san_ngan_han": ["T√†i s·∫£n ng·∫Øn h·∫°n"],
	"no_ngan_han": ["N·ª£ ng·∫Øn h·∫°n"],
	"hang_ton_kho": ["H√†ng t·ªìn kho"],
	"tien_tdt": ["Ti·ªÅn v√† c√°c kho·∫£n t∆∞∆°ng ƒë∆∞∆°ng ti·ªÅn",
"Ti·ªÅn v√† t∆∞∆°ng ƒë∆∞∆°ng ti·ªÅn"],
	"phai_thu_kh": ["Ph·∫£i thu ng·∫Øn h·∫°n c·ªßa kh√°ch h√†ng",
"Ph·∫£i thu kh√°ch h√†ng"],
	"no_dai_han_den_han": ["N·ª£ d√†i h·∫°n ƒë·∫øn h·∫°n tr·∫£",
"N·ª£ d√†i h·∫°n ƒë·∫øn h·∫°n"],
}
ALIAS_CF = {
	"khau_hao": ["Kh·∫•u hao TSCƒê", "Kh·∫•u hao",
"Chi ph√≠ kh·∫•u hao"],
}

def _pick_year_cols(df: pd.DataFrame):
	"""Ch·ªçn 2 c·ªôt nƒÉm g·∫ßn nh·∫•t t·ª´ sheet (∆∞u ti√™n c·ªôt c√≥ nh√£n
l√† nƒÉm)."""
	numeric_years = []
	for c in df.columns[1:]:
		try:
			y = int(float(str(c).strip()))
			if 1990 <= y <= 2100:
				 numeric_years.append((y, c))
		except Exception:
			continue
	if numeric_years:
		numeric_years.sort(key=lambda x: x[0])
		return numeric_years[-2][1], numeric_years[-1][1]
	# fallback: 2 c·ªôt cu·ªëi
	cols = df.columns[-2:]
	return cols[0], cols[1]

def _get_row_vals(df: pd.DataFrame,
aliases: list[str]):
	"""T√¨m d√≤ng theo alias (contains, kh√¥ng ph√¢n bi·ªát hoa/th∆∞·ªùng).
Tr·∫£ v·ªÅ (prev, cur) theo 2 c·ªôt nƒÉm g·∫ßn nh·∫•t."""
	label_col = df.columns[0]
	prev_col, cur_col = _pick_year_cols(df)
	mask = False
	for alias in aliases:
		mask = mask | df[label_col].astype(str).str.contains(alias, case=False,
na=False)
	rows = df[mask]
	if rows.empty:
		return np.nan, np.nan
	row = rows.iloc[0]

	def to_num(x):
		try:
			return float(str(x).replace(",", "").replace("
", ""))
		except Exception:
			return np.nan

	return to_num(row[prev_col]), to_num(row[cur_col])

def
compute_ratios_from_three_sheets(xlsx_file) -> pd.DataFrame:
	"""ƒê·ªçc 3 sheet CDKT/BCTN/LCTT v√† t√≠nh X1..X14 theo y√™u c·∫ßu."""
	# ƒê·ªçc 3 sheet; c·∫ßn openpyxl trong requirements
	bs = pd.read_excel(xlsx_file, sheet_name="CDKT",
engine="openpyxl")
	is_ = pd.read_excel(xlsx_file, sheet_name="BCTN",
engine="openpyxl")
	cf = pd.read_excel(xlsx_file, sheet_name="LCTT",
engine="openpyxl")

	# ---- KQKD (BCTN)
	DTT_prev, DTT_cur	=
_get_row_vals(is_, ALIAS_IS["doanh_thu_thuan"])
	GVHB_prev, GVHB_cur = _get_row_vals(is_, ALIAS_IS["gia_von"])
	LNG_prev, LNG_cur	=
_get_row_vals(is_, ALIAS_IS["loi_nhuan_gop"])
	LNTT_prev, LNTT_cur = _get_row_vals(is_,
ALIAS_IS["loi_nhuan_truoc_thue"])
	LV_prev, LV_cur		=
_get_row_vals(is_, ALIAS_IS["chi_phi_lai_vay"])

	# ---- CƒêKT (CDKT)
	TTS_prev, TTS_cur		=
_get_row_vals(bs, ALIAS_BS["tong_tai_san"])
	VCSH_prev, VCSH_cur	=
_get_row_vals(bs, ALIAS_BS["von_chu_so_huu"])
	NPT_prev, NPT_cur		=
_get_row_vals(bs, ALIAS_BS["no_phai_tra"])
	TSNH_prev, TSNH_cur	=
_get_row_vals(bs, ALIAS_BS["tai_san_ngan_han"])
	NNH_prev, NNH_cur		=
_get_row_vals(bs, ALIAS_BS["no_ngan_han"])
	HTK_prev, HTK_cur		=
_get_row_vals(bs, ALIAS_BS["hang_ton_kho"])
	Tien_prev, Tien_cur	=
_get_row_vals(bs, ALIAS_BS["tien_tdt"])
	KPT_prev, KPT_cur		=
_get_row_vals(bs, ALIAS_BS["phai_thu_kh"])
	NDH_prev, NDH_cur		=
_get_row_vals(bs, ALIAS_BS["no_dai_han_den_han"])

	# ---- LCTT (LCTT) ‚Äì l·∫•y Kh·∫•u hao n·∫øu c√≥
	KH_prev, KH_cur = _get_row_vals(cf, ALIAS_CF["khau_hao"])

	# Chu·∫©n ho√° s·ªë √¢m th∆∞·ªùng th·∫•y ·ªü GVHB, chi ph√≠ l√£i vay, kh·∫•u hao
	if pd.notna(GVHB_cur): GVHB_cur = abs(GVHB_cur)
	if pd.notna(LV_cur):	LV_cur	= abs(LV_cur)
	if pd.notna(KH_cur):	KH_cur	= abs(KH_cur)

	# Trung b√¨nh ƒë·∫ßu/cu·ªëi k·ª≥
	def avg(a, b):
		if pd.isna(a) and pd.isna(b): return np.nan
		if pd.isna(a): return b
		if pd.isna(b): return a
		return (a + b) / 2.0
	TTS_avg	 = avg(TTS_cur,	 TTS_prev)
	VCSH_avg = avg(VCSH_cur, VCSH_prev)
	HTK_avg	 = avg(HTK_cur,	 HTK_prev)
	KPT_avg	 = avg(KPT_cur,	 KPT_prev)

	# EBIT ~ LNTT + chi ph√≠ l√£i vay (n·∫øu thi·∫øu EBIT ri√™ng)
	EBIT_cur = (LNTT_cur + LV_cur) if (pd.notna(LNTT_cur) and
pd.notna(LV_cur)) else np.nan
	# N·ª£ d√†i h·∫°n ƒë·∫øn h·∫°n tr·∫£: c√≥ file kh√¥ng ghi -> set 0
	NDH_cur = 0.0 if pd.isna(NDH_cur) else NDH_cur

	def div(a, b):
		return np.nan if (b is None or pd.isna(b) or b == 0) else a / b

	# ==== T√çNH X1..X14 ====
	X1	= div(LNG_cur, DTT_cur)					# Bi√™n LN g·ªôp
	X2	= div(LNTT_cur, DTT_cur)				# Bi√™n LNTT
	X3	= div(LNTT_cur, TTS_avg)				# ROA (tr∆∞·ªõc thu·∫ø)
	X4	= div(LNTT_cur, VCSH_avg)				# ROE (tr∆∞·ªõc thu·∫ø)
	X5	= div(NPT_cur,	TTS_cur)				# N·ª£/T√†i s·∫£n
	X6	= div(NPT_cur,	VCSH_cur)				# N·ª£/VCSH
	X7	= div(TSNH_cur, NNH_cur)				# Thanh to√°n hi·ªán h√†nh
	X8	= div((TSNH_cur - HTK_cur) if
pd.notna(TSNH_cur) and pd.notna(HTK_cur) else np.nan, NNH_cur)	# Nhanh
	X9	= div(EBIT_cur, LV_cur)					# Kh·∫£ nƒÉng tr·∫£ l√£i
	X10 = div((EBIT_cur + (KH_cur if pd.notna(KH_cur) else 0.0)),
				 (LV_cur + NDH_cur) if
pd.notna(LV_cur) else np.nan)	# Kh·∫£ nƒÉng
# tr·∫£ n·ª£ g·ªëc
	X11 = div(Tien_cur, VCSH_cur)					# Ti·ªÅn/VCSH
	X12 = div(GVHB_cur, HTK_avg)					# V√≤ng quay HTK
	turnover = div(DTT_cur, KPT_avg)				# V√≤ng quay ph·∫£i thu
	X13 = div(365.0, turnover) if pd.notna(turnover) and turnover != 0 else
np.nan	# K·ª≥ thu ti·ªÅn BQ
	X14 = div(DTT_cur, TTS_avg)					# Hi·ªáu su·∫•t s·ª≠ d·ª•ng t√†i s·∫£n

	ratios = pd.DataFrame([[X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11,
X12, X13, X14]],
								 columns=[f"X_{i}" for i in range(1, 15)])
	return ratios

# =========================
# UI & TRAIN MODEL
# =========================
np.random.seed(0)
st.title("D·ª∞ B√ÅO THAM S·ªê PD")
st.write("## D·ª± b√°o x√°c su·∫•t v·ª° n·ª£ c·ªßa
kh√°ch h√†ng_PD")

# Hi·ªÉn th·ªã tr·∫°ng th√°i th∆∞ vi·ªán AI
st.caption("üîé
Tr·∫°ng th√°i Gemini: " + ("‚úÖ s·∫µn s√†ng (c·∫ßn 'GEMINI_API_KEY'
trong Secrets)" if _GEMINI_OK else "‚ö†Ô∏è Thi·∫øu th∆∞ vi·ªán
google-genai."))

# Load d·ªØ li·ªáu hu·∫•n luy·ªán (CSV
