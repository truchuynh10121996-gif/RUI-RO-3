# app_upgraded.py ‚Äî Streamlit PD + Ph√¢n t√≠ch Gemini (Giao di·ªán n√¢ng c·∫•p)

# =========================
# TH∆Ø VI·ªÜN B·∫ÆT BU·ªòC V√Ä B·ªî SUNG
# =========================
from datetime import datetime
import os
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    confusion_matrix,
    f1_score,
    accuracy_score,
    recall_score,
    precision_score,
    roc_auc_score,
    ConfusionMatrixDisplay,
)

# Th∆∞ vi·ªán GOOGLE GEMINI V√Ä OPENAI (Gi·ªØ nguy√™n logic ki·ªÉm tra th∆∞ vi·ªán)
try:
    from google import genai
    from google.genai.errors import APIError
    _GEMINI_OK = True
except Exception:
    genai = None
    APIError = Exception
    _GEMINI_OK = False

try:
    from openai import OpenAI
    _OPENAI_OK = True
except Exception:
    OpenAI = None
    _OPENAI_OK = False


MODEL_NAME = "gemini-2.5-flash" # Model m·∫°nh m·∫Ω v√† hi·ªáu qu·∫£ cho ph√¢n t√≠ch vƒÉn b·∫£n

# =========================
# C·∫§U H√åNH TRANG (N√ÇNG C·∫§P GIAO DI·ªÜN)
# =========================
st.set_page_config(
    page_title="Credit Risk PD & Gemini Analysis",
    page_icon="üèõÔ∏è",
    layout="wide", # S·ª≠ d·ª•ng b·ªë c·ª•c r·ªông r√£i h∆°n
    initial_sidebar_state="expanded"
)

# Th√™m CSS t√πy ch·ªânh nh·∫π (Tu·ª≥ ch·ªçn: c√≥ th·ªÉ ƒë·∫∑t file .streamlit/style.css)
st.markdown("""
<style>
/* TƒÉng ƒë·ªô ƒë·∫≠m ti√™u ƒë·ªÅ ch√≠nh */
h1 {
    font-weight: 700;
    color: #1E90FF; /* M√†u xanh d∆∞∆°ng hi·ªán ƒë·∫°i */
}
/* Th·∫ª ch√≠nh metrics */
div[data-testid="metric-container"] {
    border: 1px solid #ddd;
    border-radius: 8px;
    padding: 10px;
    box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
}
</style>
""", unsafe_allow_html=True)


# =========================
# H√ÄM G·ªåI GEMINI API (GI·ªÆ NGUY√äN)
# =========================

def get_ai_analysis(data_payload: dict, api_key: str) -> str:
    """
    S·ª≠ d·ª•ng Gemini API ƒë·ªÉ ph√¢n t√≠ch ch·ªâ s·ªë t√†i ch√≠nh.
    """
    if not _GEMINI_OK:
        return "L·ªói: Thi·∫øu th∆∞ vi·ªán google-genai (c·∫ßn c√†i ƒë·∫∑t: pip install google-genai)."

    client = genai.Client(api_key=api_key)

    sys_prompt = (
        "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch t√≠n d·ª•ng doanh nghi·ªáp t·∫°i ng√¢n h√†ng. "
        "Ph√¢n t√≠ch to√†n di·ªán d·ª±a tr√™n 14 ch·ªâ s·ªë t√†i ch√≠nh (X1..X14) v√† PD n·∫øu c√≥. "
        "N√™u r√µ: (1) Kh·∫£ nƒÉng sinh l·ªùi, (2) Thanh kho·∫£n, (3) C∆° c·∫•u n·ª£, (4) Hi·ªáu qu·∫£ ho·∫°t ƒë·ªông. "
        "K·∫øt th√∫c b·∫±ng khuy·∫øn ngh·ªã in hoa: CHO VAY ho·∫∑c KH√îNG CHO VAY, k√®m 2‚Äì3 ƒëi·ªÅu ki·ªán n·∫øu CHO VAY. "
        "Vi·∫øt b·∫±ng ti·∫øng Vi·ªát s√∫c t√≠ch, chuy√™n nghi·ªáp."
    )
    
    user_prompt = "B·ªô ch·ªâ s·ªë X1..X14 v√† PD c·∫ßn ph√¢n t√≠ch:\n" + str(data_payload) + "\n\nH√£y ph√¢n t√≠ch v√† ƒë∆∞a ra khuy·∫øn ngh·ªã."

    try:
        response = client.models.generate_content(
            model=MODEL_NAME,
            contents=[
                 {"role": "user", "parts": [{"text": sys_prompt + "\n\n" + user_prompt}]}
            ],
            config={"system_instruction": sys_prompt}
        )
        return response.text
    except APIError as e:
        return f"L·ªói g·ªçi API Gemini: {e}"
    except Exception as e:
        return f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"


# =========================
# T√çNH X1..X14 T·ª™ 3 SHEET (CDKT/BCTN/LCTT) - GI·ªÆ NGUY√äN LOGIC
# =========================

# Alias c√°c d√≤ng quan tr·ªçng trong t·ª´ng sheet (GI·ªÆ NGUY√äN)
ALIAS_IS = {
    "doanh_thu_thuan": ["Doanh thu thu·∫ßn", "Doanh thu b√°n h√†ng", "Doanh thu thu·∫ßn v·ªÅ b√°n h√†ng v√† cung c·∫•p d·ªãch v·ª•"],
    "gia_von": ["Gi√° v·ªën h√†ng b√°n"],
    "loi_nhuan_gop": ["L·ª£i nhu·∫≠n g·ªôp"],
    "chi_phi_lai_vay": ["Chi ph√≠ l√£i vay", "Chi ph√≠ t√†i ch√≠nh (trong ƒë√≥: chi ph√≠ l√£i vay)"],
    "loi_nhuan_truoc_thue": ["T·ªïng l·ª£i nhu·∫≠n k·∫ø to√°n tr∆∞·ªõc thu·∫ø", "L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø", "L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø thu nh·∫≠p DN"],
}
ALIAS_BS = {
    "tong_tai_san": ["T·ªïng t√†i s·∫£n"],
    "von_chu_so_huu": ["V·ªën ch·ªß s·ªü h·ªØu", "V·ªën CSH"],
    "no_phai_tra": ["N·ª£ ph·∫£i tr·∫£"],
    "tai_san_ngan_han": ["T√†i s·∫£n ng·∫Øn h·∫°n"],
    "no_ngan_han": ["N·ª£ ng·∫Øn h·∫°n"],
    "hang_ton_kho": ["H√†ng t·ªìn kho"],
    "tien_tdt": ["Ti·ªÅn v√† c√°c kho·∫£n t∆∞∆°ng ƒë∆∞∆°ng ti·ªÅn", "Ti·ªÅn v√† t∆∞∆°ng ƒë∆∞∆°ng ti·ªÅn"],
    "phai_thu_kh": ["Ph·∫£i thu ng·∫Øn h·∫°n c·ªßa kh√°ch h√†ng", "Ph·∫£i thu kh√°ch h√†ng"],
    "no_dai_han_den_han": ["N·ª£ d√†i h·∫°n ƒë·∫øn h·∫°n tr·∫£", "N·ª£ d√†i h·∫°n ƒë·∫øn h·∫°n"],
}
ALIAS_CF = {
    "khau_hao": ["Kh·∫•u hao TSCƒê", "Kh·∫•u hao", "Chi ph√≠ kh·∫•u hao"],
}

def _pick_year_cols(df: pd.DataFrame):
    """Ch·ªçn 2 c·ªôt nƒÉm g·∫ßn nh·∫•t t·ª´ sheet (∆∞u ti√™n c·ªôt c√≥ nh√£n l√† nƒÉm)."""
    numeric_years = []
    for c in df.columns[1:]:
        try:
            y = int(float(str(c).strip()))
            if 1990 <= y <= 2100:
                numeric_years.append((y, c))
        except Exception:
            continue
    if numeric_years:
        numeric_years.sort(key=lambda x: x[0])
        return numeric_years[-2][1], numeric_years[-1][1]
    # fallback: 2 c·ªôt cu·ªëi
    cols = df.columns[-2:]
    return cols[0], cols[1]

def _get_row_vals(df: pd.DataFrame, aliases: list[str]):
    """T√¨m d√≤ng theo alias (contains, kh√¥ng ph√¢n bi·ªát hoa/th∆∞·ªùng). Tr·∫£ v·ªÅ (prev, cur) theo 2 c·ªôt nƒÉm g·∫ßn nh·∫•t."""
    label_col = df.columns[0]
    prev_col, cur_col = _pick_year_cols(df)
    mask = False
    for alias in aliases:
        mask = mask | df[label_col].astype(str).str.contains(alias, case=False, na=False)
    rows = df[mask]
    if rows.empty:
        return np.nan, np.nan
    row = rows.iloc[0]

    def to_num(x):
        try:
            return float(str(x).replace(",", "").replace(" ", ""))
        except Exception:
            return np.nan

    return to_num(row[prev_col]), to_num(row[cur_col])

def compute_ratios_from_three_sheets(xlsx_file) -> pd.DataFrame:
    """ƒê·ªçc 3 sheet CDKT/BCTN/LCTT v√† t√≠nh X1..X14 theo y√™u c·∫ßu. (GI·ªÆ NGUY√äN)"""
    # ƒê·ªçc 3 sheet; c·∫ßn openpyxl trong requirements
    bs = pd.read_excel(xlsx_file, sheet_name="CDKT", engine="openpyxl")
    is_ = pd.read_excel(xlsx_file, sheet_name="BCTN", engine="openpyxl")
    cf = pd.read_excel(xlsx_file, sheet_name="LCTT", engine="openpyxl")

    # ---- KQKD (BCTN)
    DTT_prev, DTT_cur    = _get_row_vals(is_, ALIAS_IS["doanh_thu_thuan"])
    GVHB_prev, GVHB_cur = _get_row_vals(is_, ALIAS_IS["gia_von"])
    LNG_prev, LNG_cur    = _get_row_vals(is_, ALIAS_IS["loi_nhuan_gop"])
    LNTT_prev, LNTT_cur = _get_row_vals(is_, ALIAS_IS["loi_nhuan_truoc_thue"])
    LV_prev, LV_cur      = _get_row_vals(is_, ALIAS_IS["chi_phi_lai_vay"])

    # ---- CƒêKT (CDKT)
    TTS_prev, TTS_cur      = _get_row_vals(bs, ALIAS_BS["tong_tai_san"])
    VCSH_prev, VCSH_cur    = _get_row_vals(bs, ALIAS_BS["von_chu_so_huu"])
    NPT_prev, NPT_cur      = _get_row_vals(bs, ALIAS_BS["no_phai_tra"])
    TSNH_prev, TSNH_cur    = _get_row_vals(bs, ALIAS_BS["tai_san_ngan_han"])
    NNH_prev, NNH_cur      = _get_row_vals(bs, ALIAS_BS["no_ngan_han"])
    HTK_prev, HTK_cur      = _get_row_vals(bs, ALIAS_BS["hang_ton_kho"])
    Tien_prev, Tien_cur    = _get_row_vals(bs, ALIAS_BS["tien_tdt"])
    KPT_prev, KPT_cur      = _get_row_vals(bs, ALIAS_BS["phai_thu_kh"])
    NDH_prev, NDH_cur      = _get_row_vals(bs, ALIAS_BS["no_dai_han_den_han"])

    # ---- LCTT (LCTT) ‚Äì l·∫•y Kh·∫•u hao n·∫øu c√≥
    KH_prev, KH_cur = _get_row_vals(cf, ALIAS_CF["khau_hao"])

    # Chu·∫©n ho√° s·ªë √¢m th∆∞·ªùng th·∫•y ·ªü GVHB, chi ph√≠ l√£i vay, kh·∫•u hao
    if pd.notna(GVHB_cur): GVHB_cur = abs(GVHB_cur)
    if pd.notna(LV_cur):   LV_cur    = abs(LV_cur)
    if pd.notna(KH_cur):   KH_cur    = abs(KH_cur)

    # Trung b√¨nh ƒë·∫ßu/cu·ªëi k·ª≥
    def avg(a, b):
        if pd.isna(a) and pd.isna(b): return np.nan
        if pd.isna(a): return b
        if pd.isna(b): return a
        return (a + b) / 2.0
    TTS_avg  = avg(TTS_cur,  TTS_prev)
    VCSH_avg = avg(VCSH_cur, VCSH_prev)
    HTK_avg  = avg(HTK_cur,  HTK_prev)
    KPT_avg  = avg(KPT_cur,  KPT_prev)

    # EBIT ~ LNTT + chi ph√≠ l√£i vay (n·∫øu thi·∫øu EBIT ri√™ng)
    EBIT_cur = (LNTT_cur + LV_cur) if (pd.notna(LNTT_cur) and pd.notna(LV_cur)) else np.nan
    # N·ª£ d√†i h·∫°n ƒë·∫øn h·∫°n tr·∫£: c√≥ file kh√¥ng ghi -> set 0
    NDH_cur = 0.0 if pd.isna(NDH_cur) else NDH_cur

    def div(a, b):
        return np.nan if (b is None or pd.isna(b) or b == 0) else a / b

    # ==== T√çNH X1..X14 ====
    X1  = div(LNG_cur, DTT_cur)                      # Bi√™n LN g·ªôp
    X2  = div(LNTT_cur, DTT_cur)                     # Bi√™n LNTT
    X3  = div(LNTT_cur, TTS_avg)                     # ROA (tr∆∞·ªõc thu·∫ø)
    X4  = div(LNTT_cur, VCSH_avg)                    # ROE (tr∆∞·ªõc thu·∫ø)
    X5  = div(NPT_cur,  TTS_cur)                     # N·ª£/T√†i s·∫£n
    X6  = div(NPT_cur,  VCSH_cur)                    # N·ª£/VCSH
    X7  = div(TSNH_cur, NNH_cur)                     # Thanh to√°n hi·ªán h√†nh
    X8  = div((TSNH_cur - HTK_cur) if pd.notna(TSNH_cur) and pd.notna(HTK_cur) else np.nan, NNH_cur)  # Nhanh
    X9  = div(EBIT_cur, LV_cur)                      # Kh·∫£ nƒÉng tr·∫£ l√£i
    X10 = div((EBIT_cur + (KH_cur if pd.notna(KH_cur) else 0.0)),
              (LV_cur + NDH_cur) if pd.notna(LV_cur) else np.nan)  # Kh·∫£ nƒÉng tr·∫£ n·ª£ g·ªëc
    X11 = div(Tien_cur, VCSH_cur)                    # Ti·ªÅn/VCSH
    X12 = div(GVHB_cur, HTK_avg)                     # V√≤ng quay HTK
    turnover = div(DTT_cur, KPT_avg)               # V√≤ng quay ph·∫£i thu
    X13 = div(365.0, turnover) if pd.notna(turnover) and turnover != 0 else np.nan  # K·ª≥ thu ti·ªÅn BQ
    X14 = div(DTT_cur, TTS_avg)                      # Hi·ªáu su·∫•t s·ª≠ d·ª•ng t√†i s·∫£n

    ratios = pd.DataFrame([[X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14]],
                         columns=[f"X_{i}" for i in range(1, 15)])
    return ratios

# =========================
# UI & TRAIN MODEL
# =========================
np.random.seed(0)

# ·∫®n menu v√† footer m·∫∑c ƒë·ªãnh c·ªßa Streamlit (TƒÉng t√≠nh chuy√™n nghi·ªáp)
hide_streamlit_style = """
<style>
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)


st.title("üèõÔ∏è H·ªÜ TH·ªêNG ƒê√ÅNH GI√Å R·ª¶I RO T√çN D·ª§NG DOANH NGHI·ªÜP")
st.write("### D·ª± b√°o X√°c su·∫•t V·ª° n·ª£ (PD) & Ph√¢n t√≠ch T√†i ch√≠nh n√¢ng cao")

# Hi·ªÉn th·ªã tr·∫°ng th√°i th∆∞ vi·ªán AI (S·ª≠ d·ª•ng c·ªôt ƒë·ªÉ b·ªë tr√≠ ƒë·∫πp h∆°n)
col_ai_status, col_date = st.columns([3, 1])
with col_ai_status:
    ai_status = ("‚úÖ s·∫µn s√†ng (c·∫ßn 'GEMINI_API_KEY' trong Secrets)" if _GEMINI_OK else "‚ö†Ô∏è Thi·∫øu th∆∞ vi·ªán google-genai.")
    st.caption(f"üîé Tr·∫°ng th√°i Gemini AI: **{ai_status}**")
with col_date:
    st.caption(f"üìÖ C·∫≠p nh·∫≠t: {datetime.now().strftime('%d/%m/%Y %H:%M')}")

st.divider()

# Load d·ªØ li·ªáu hu·∫•n luy·ªán (CSV c√≥ default, X_1..X_14) - Gi·ªØ nguy√™n logic load data
try:
    df = pd.read_csv('DATASET.csv', encoding='latin-1')
except Exception:
    df = None

uploaded_file = st.sidebar.file_uploader("üìÇ T·∫£i CSV D·ªØ li·ªáu Hu·∫•n luy·ªán", type=['csv'])
if uploaded_file is not None:
    df = pd.read_csv(uploaded_file, encoding='latin-1')

if df is None:
    st.sidebar.info("üí° H√£y t·∫£i file CSV hu·∫•n luy·ªán (c√≥ c·ªôt 'default' v√† X_1...X_14) ƒë·ªÉ x√¢y d·ª±ng m√¥ h√¨nh.")
    
    # Hi·ªÉn th·ªã dashboard m·∫∑c ƒë·ªãnh cho ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu
    st.markdown("## üéØ M·ª•c ti√™u ·ª®ng d·ª•ng")
    st.info("**·ª®ng d·ª•ng n√†y gi√∫p b·∫°n: (1) Hu·∫•n luy·ªán m√¥ h√¨nh Logistic Regression d·ª± b√°o X√°c su·∫•t V·ª° n·ª£ (PD) t·ª´ b·ªô 14 ch·ªâ s·ªë t√†i ch√≠nh (X1-X14). (2) Ph√¢n t√≠ch chuy√™n s√¢u c√°c ch·ªâ s·ªë t√†i ch√≠nh b·∫±ng m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn Gemini AI.**")
    st.stop()

# Ki·ªÉm tra c·ªôt c·∫ßn thi·∫øt
required_cols = ['default'] + [f"X_{i}" for i in range(1, 15)]
missing = [c for c in required_cols if c not in df.columns]
if missing:
    st.error(f"‚ùå Thi·∫øu c·ªôt: **{missing}**. Vui l√≤ng ki·ªÉm tra l·∫°i file CSV hu·∫•n luy·ªán.")
    st.stop()


# Train model (GI·ªÆ NGUY√äN)
X = df.drop(columns=['default'])
y = df['default'].astype(int)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
model = LogisticRegression(random_state=42, max_iter=1000, class_weight="balanced", solver="lbfgs")
model.fit(X_train, y_train)

# D·ª± b√°o & ƒë√°nh gi√° (GI·ªÆ NGUY√äN)
y_pred_in = model.predict(X_train)
y_proba_in = model.predict_proba(X_train)[:, 1]
y_pred_out = model.predict(X_test)
y_proba_out = model.predict_proba(X_test)[:, 1]

metrics_in = {
    "accuracy_in": accuracy_score(y_train, y_pred_in),
    "precision_in": precision_score(y_train, y_pred_in, zero_division=0),
    "recall_in": recall_score(y_train, y_pred_in, zero_division=0),
    "f1_in": f1_score(y_train, y_pred_in, zero_division=0),
    "auc_in": roc_auc_score(y_train, y_proba_in),
}
metrics_out = {
    "accuracy_out": accuracy_score(y_test, y_pred_out),
    "precision_out": precision_score(y_test, y_pred_out, zero_division=0),
    "recall_out": recall_score(y_test, y_pred_out, zero_division=0),
    "f1_out": f1_score(y_test, y_pred_out, zero_division=0),
    "auc_out": roc_auc_score(y_test, y_proba_out),
}

# S·ª≠ d·ª•ng Sidebar ƒë·ªÉ ch·ªçn t√≠nh nƒÉng (Gi·ªØ nguy√™n)
menu = ["M·ª•c ti√™u c·ªßa m√¥ h√¨nh", "X√¢y d·ª±ng m√¥ h√¨nh", "S·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ d·ª± b√°o"]
choice = st.sidebar.selectbox('üöÄ Danh m·ª•c T√≠nh nƒÉng', menu)

# --- C√°c ph·∫ßn UI ƒë∆∞·ª£c t·ªï ch·ª©c l·∫°i ƒë·∫πp h∆°n ---

if choice == 'M·ª•c ti√™u c·ªßa m√¥ h√¨nh':    
    st.header("üéØ M·ª•c ti√™u c·ªßa M√¥ h√¨nh")
    st.markdown("**D·ª± b√°o x√°c su·∫•t v·ª° n·ª£ (PD) c·ªßa kh√°ch h√†ng doanh nghi·ªáp** d·ª±a tr√™n b·ªô ch·ªâ s·ªë X1‚ÄìX14 (t√≠nh t·ª´ B·∫£ng C√¢n ƒë·ªëi K·∫ø to√°n, B√°o c√°o K·∫øt qu·∫£ Kinh doanh v√† B√°o c√°o L∆∞u chuy·ªÉn Ti·ªÅn t·ªá).")
    
    # Hi·ªÉn th·ªã h√¨nh ·∫£nh minh h·ªça trong expander (tr√°nh l√†m r·ªëi m√†n h√¨nh ch√≠nh)
    with st.expander("üñºÔ∏è M√¥ t·∫£ tr·ª±c quan m√¥ h√¨nh"):
        st.markdown("ƒê√¢y l√† c√°c h√¨nh ·∫£nh minh h·ªça cho m√¥ h√¨nh H·ªìi quy Logistic v√† c√°c giai ƒëo·∫°n ƒë√°nh gi√° r·ªßi ro.")
        # ·∫£nh minh h·ªça (c√≥ th·ªÉ kh√¥ng t·ªìn t·∫°i) - GI·ªÆ NGUY√äN C√ÅCH LOAD
        for img in ["hinh2.jpg", "LogReg_1.png", "hinh3.png"]:
            try:
                st.image(img)
            except Exception:
                st.warning(f"Kh√¥ng t√¨m th·∫•y {img}")

elif choice == 'X√¢y d·ª±ng m√¥ h√¨nh':
    st.header("üõ†Ô∏è X√¢y d·ª±ng & ƒê√°nh gi√° M√¥ h√¨nh LogReg")
    st.info("M√¥ h√¨nh H·ªìi quy Logistic ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n **20% d·ªØ li·ªáu Test (ch∆∞a th·∫•y)**.")
    
    # Hi·ªÉn th·ªã Metrics quan tr·ªçng b·∫±ng st.metric
    st.subheader("1. T·ªïng quan K·∫øt qu·∫£ ƒê√°nh gi√° (Test Set)")
    col_acc, col_auc, col_f1 = st.columns(3)
    
    col_acc.metric(label="ƒê·ªô ch√≠nh x√°c (Accuracy)", value=f"{metrics_out['accuracy_out']:.2%}")
    col_auc.metric(label="Di·ªán t√≠ch d∆∞·ªõi ƒë∆∞·ªùng cong (AUC)", value=f"{metrics_out['auc_out']:.3f}", delta=f"{metrics_out['auc_in'] - metrics_out['auc_out']:.3f}", delta_color="inverse")
    col_f1.metric(label="ƒêi·ªÉm F1-Score", value=f"{metrics_out['f1_out']:.3f}")
    
    st.divider()

    # Th·ªëng k√™ chi ti·∫øt & Bi·ªÉu ƒë·ªì
    st.subheader("2. D·ªØ li·ªáu v√† Tr·ª±c quan h√≥a")
    
    with st.expander("üìä Th·ªëng k√™ M√¥ t·∫£ v√† D·ªØ li·ªáu M·∫´u"):
        st.markdown("##### Th·ªëng k√™ M√¥ t·∫£ c√°c bi·∫øn X1..X14")
        st.dataframe(df[[f"X_{i}" for i in range(1, 15)]].describe().style.format("{:.4f}"))
        st.markdown("##### 6 D√≤ng d·ªØ li·ªáu hu·∫•n luy·ªán m·∫´u (ƒê·∫ßu/Cu·ªëi)")
        st.dataframe(pd.concat([df.head(3), df.tail(3)]))

    st.markdown("##### Bi·ªÉu ƒë·ªì Ph√¢n t√°n (Scatter Plot) v·ªõi ƒê∆∞·ªùng H·ªìi quy Logisitc")
    col = st.selectbox('üîç Ch·ªçn bi·∫øn X mu·ªën v·∫Ω', options=[f"X_{i}" for i in range(1, 15)], index=0)

    # Bi·ªÉu ƒë·ªì Scatter Plot v√† ƒê∆∞·ªùng H·ªìi quy Logisitc (GI·ªÆ NGUY√äN LOGIC)
    if col in df.columns:
        try:
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.scatterplot(data=df, x=col, y='default', alpha=0.6, ax=ax, hue='default', palette=['green', 'red'])
            
            # V·∫Ω ƒë∆∞·ªùng logistic regression theo 1 bi·∫øn
            x_range = np.linspace(df[col].min(), df[col].max(), 100).reshape(-1, 1)
            X_temp = df[[col]].copy()
            y_temp = df['default']
            lr_temp = LogisticRegression(max_iter=1000)
            lr_temp.fit(X_temp, y_temp)
            x_test = pd.DataFrame({col: x_range[:, 0]})
            y_curve = lr_temp.predict_proba(x_test)[:, 1]
            ax.plot(x_range, y_curve, color='blue', linewidth=3, label='ƒê∆∞·ªùng LogReg')
            
            ax.set_title(f'Quan h·ªá gi·ªØa {col} v√† X√°c su·∫•t V·ª° n·ª£', fontsize=14)
            ax.set_ylabel('X√°c su·∫•t default (1: Default)', fontsize=12)
            ax.set_xlabel(col, fontsize=12)
            ax.legend(title='Default')
            st.pyplot(fig)
            plt.close(fig) # ƒê√≥ng figure ƒë·ªÉ tr√°nh c·∫£nh b√°o b·ªô nh·ªõ
        except Exception as e:
            st.error(f"L·ªói khi v·∫Ω bi·ªÉu ƒë·ªì: {e}")
    else:
        st.warning("Bi·∫øn kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu.")
    
    st.divider()

    st.subheader("3. Ma tr·∫≠n Nh·∫ßm l·∫´n v√† B·∫£ng Metrics Chi ti·∫øt")
    col_cm, col_metrics_table = st.columns(2)
    
    with col_cm:
        st.markdown("##### Ma tr·∫≠n Nh·∫ßm l·∫´n (Test Set)")
        cm = confusion_matrix(y_test, y_pred_out)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Default (0)', 'Default (1)'])
        fig2, ax = plt.subplots(figsize=(6, 6))
        disp.plot(ax=ax, cmap=plt.cm.Blues) # S·ª≠ d·ª•ng m√†u s·∫Øc chuy√™n nghi·ªáp h∆°n
        st.pyplot(fig2)
        plt.close(fig2)
        
    with col_metrics_table:
        st.markdown("##### B·∫£ng Metrics Chi ti·∫øt")
        dt = pd.DataFrame({
            "Metric": ["Accuracy", "Precision", "Recall", "F1-Score", "AUC"],
            "Train Set": [metrics_in['accuracy_in'], metrics_in['precision_in'], metrics_in['recall_in'], metrics_in['f1_in'], metrics_in['auc_in']],
            "Test Set": [metrics_out['accuracy_out'], metrics_out['precision_out'], metrics_out['recall_out'], metrics_out['f1_out'], metrics_out['auc_out']],
        }).set_index("Metric")
        st.dataframe(dt.style.format("{:.4f}"))

elif choice == 'S·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ d·ª± b√°o':
    st.header("‚ö° D·ª± b√°o PD & Ph√¢n t√≠ch AI cho H·ªì s∆° m·ªõi")
    
    # S·ª≠ d·ª•ng st.container v√† st.expander ƒë·ªÉ t·ªï ch·ª©c khu v·ª±c upload
    input_container = st.container(border=True)
    with input_container:
        st.markdown("##### üì• T·∫£i l√™n H·ªì s∆° Doanh nghi·ªáp (Excel)")
        st.caption("File ph·∫£i c√≥ ƒë·ªß **3 sheet**: **CDKT** (B·∫£ng C√¢n ƒë·ªëi K·∫ø to√°n) ; **BCTN** (B√°o c√°o K·∫øt qu·∫£ Kinh doanh) ; **LCTT** (B√°o c√°o L∆∞u chuy·ªÉn Ti·ªÅn t·ªá).")
        up_xlsx = st.file_uploader("T·∫£i **ho_so_dn.xlsx**", type=["xlsx"], key="ho_so_dn", label_visibility="collapsed")
    
    if up_xlsx is not None:
        # T√≠nh X1..X14 t·ª´ 3 sheet (GI·ªÆ NGUY√äN)
        try:
            ratios_df = compute_ratios_from_three_sheets(up_xlsx)
        except Exception as e:
            st.error(f"‚ùå L·ªói t√≠nh X1‚Ä¶X14: Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u tr√∫c 3 sheet trong file Excel. Chi ti·∫øt l·ªói: {e}")
            st.stop()

        st.divider()
        st.markdown("### 1. üî¢ Ch·ªâ s·ªë X1‚Ä¶X14 ƒê√£ t√≠nh")
        
        # T·∫°o payload data v√† d·ª± b√°o PD (GI·ªÆ NGUY√äN)
        data_for_ai = ratios_df.iloc[0].to_dict()
        
        # (Tu·ª≥ ch·ªçn) d·ª± b√°o PD n·∫øu m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán ƒë√∫ng c·∫•u tr√∫c X_1..X_14
        probs = np.nan
        preds = np.nan
        if set(X.columns) == set(ratios_df.columns):
            try:
                probs = model.predict_proba(ratios_df[X.columns])[:, 1]
                preds = (probs >= 0.5).astype(int)
                data_for_ai['PD_Probability'] = probs[0]
                data_for_ai['PD_Prediction'] = "Default (V·ª° n·ª£)" if preds[0] == 1 else "Non-Default (Kh√¥ng v·ª° n·ª£)"
            except Exception as e:
                st.warning(f"Kh√¥ng d·ª± b√°o ƒë∆∞·ª£c PD: {e}")
        
        # Hi·ªÉn th·ªã X1-X14 v√† PD trong 2 c·ªôt
        col_ratios, col_pd = st.columns([3, 1])
        
        with col_ratios:
            st.dataframe(ratios_df.style.format("{:.4f}"))
            
        with col_pd:
            pd_value = f"{probs[0]:.2%}" if pd.notna(probs) else "N/A"
            pd_caption = "D·ª± b√°o V·ª° n·ª£" if pd.notna(preds) and preds[0] == 1 else "D·ª± b√°o Kh√¥ng V·ª° n·ª£"
            pd_delta = "‚¨ÜÔ∏è R·ªßi ro cao" if pd.notna(preds) and preds[0] == 1 else "‚¨áÔ∏è R·ªßi ro th·∫•p"
            
            st.metric(
                label="**X√°c su·∫•t V·ª° n·ª£ (PD)**",
                value=pd_value,
                delta=pd_delta if pd.notna(probs) else None,
                delta_color=("inverse" if pd.notna(preds) and preds[0] == 1 else "normal") # M√†u ƒë·ªè cho r·ªßi ro cao (inverse)
            )
            
        st.divider()

        # Khu v·ª±c Ph√¢n t√≠ch AI
        st.markdown("### 2. üß† Ph√¢n t√≠ch AI & Khuy·∫øn ngh·ªã T√≠n d·ª•ng")
        
        ai_container = st.container(border=True)
        with ai_container:
            st.markdown("S·ª≠ d·ª•ng Gemini AI ƒë·ªÉ ph√¢n t√≠ch to√†n di·ªán c√°c ch·ªâ s·ªë v√† ƒë∆∞a ra khuy·∫øn ngh·ªã chuy√™n nghi·ªáp.")
            
            if st.button("‚ú® Y√™u c·∫ßu AI Ph√¢n t√≠ch & ƒê·ªÅ xu·∫•t", use_container_width=True, type="primary"):
                api_key = st.secrets.get("GEMINI_API_KEY")
                
                if api_key:
                    with st.spinner('ƒêang g·ª≠i d·ªØ li·ªáu v√† ch·ªù Gemini ph√¢n t√≠ch...'):
                        ai_result = get_ai_analysis(data_for_ai, api_key)
                    
                    # T√°ch khuy·∫øn ngh·ªã ƒë·ªÉ l√†m n·ªïi b·∫≠t
                    if "KH√îNG CHO VAY" in ai_result.upper():
                        st.error("üö® **KHUY·∫æN NGH·ªä CU·ªêI C√ôNG: KH√îNG CHO VAY**")
                    elif "CHO VAY" in ai_result.upper():
                        st.success("‚úÖ **KHUY·∫æN NGH·ªä CU·ªêI C√ôNG: CHO VAY**")
                    else:
                        st.info("üí° **KHUY·∫æN NGH·ªä CU·ªêI C√ôNG**")
                        
                    st.markdown("**K·∫øt qu·∫£ Ph√¢n t√≠ch Chi ti·∫øt t·ª´ Gemini AI:**")
                    st.info(ai_result)
                else:
                    st.error("‚ùå **L·ªói Kh√≥a API**: Kh√¥ng t√¨m th·∫•y Kh√≥a API. Vui l√≤ng c·∫•u h√¨nh Kh√≥a **'GEMINI_API_KEY'** trong Streamlit Secrets.")

    else:
        st.info("H√£y t·∫£i **ho_so_dn.xlsx** (ƒë·ªß 3 sheet) ƒë·ªÉ t√≠nh X1‚Ä¶X14, d·ª± b√°o PD v√† ph√¢n t√≠ch AI.")
