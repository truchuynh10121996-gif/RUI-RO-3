# app.py ‚Äî Streamlit PD + Ph√¢n t√≠ch Gemini (N√ÇNG C·∫§P GIAO DI·ªÜN)

from datetime import datetime
import os
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    confusion_matrix,
    f1_score,
    accuracy_score,
    recall_score,
    precision_score,
    roc_auc_score,
    ConfusionMatrixDisplay,
)

# =========================
# TH∆Ø VI·ªÜN GEMINI
# =========================
try:
    from google import genai
    from google.genai.errors import APIError
    _GEMINI_OK = True
except Exception:
    genai = None
    APIError = Exception
    _GEMINI_OK = False

MODEL_NAME = "gemini-2.0-flash-exp"

# =========================
# H√ÄM G·ªåI GEMINI API
# =========================
def get_ai_analysis(data_payload: dict, api_key: str) -> str:
    """S·ª≠ d·ª•ng Gemini API ƒë·ªÉ ph√¢n t√≠ch ch·ªâ s·ªë t√†i ch√≠nh."""
    if not _GEMINI_OK:
        return "L·ªói: Thi·∫øu th∆∞ vi·ªán google-genai (c·∫ßn c√†i ƒë·∫∑t: pip install google-genai)."

    client = genai.Client(api_key=api_key)

    sys_prompt = (
        "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch t√≠n d·ª•ng doanh nghi·ªáp t·∫°i ng√¢n h√†ng v·ªõi 15 nƒÉm kinh nghi·ªám. "
        "Ph√¢n t√≠ch to√†n di·ªán d·ª±a tr√™n 14 ch·ªâ s·ªë t√†i ch√≠nh (X1..X14) v√† x√°c su·∫•t v·ª° n·ª£ (PD). "
        "N√™u r√µ: (1) Kh·∫£ nƒÉng sinh l·ªùi, (2) Thanh kho·∫£n, (3) C∆° c·∫•u n·ª£, (4) Hi·ªáu qu·∫£ ho·∫°t ƒë·ªông. "
        "K·∫øt th√∫c b·∫±ng khuy·∫øn ngh·ªã in hoa: **CHO VAY** ho·∫∑c **KH√îNG CHO VAY**, k√®m 2‚Äì3 ƒëi·ªÅu ki·ªán c·ª• th·ªÉ n·∫øu CHO VAY. "
        "Vi·∫øt b·∫±ng ti·∫øng Vi·ªát s√∫c t√≠ch, chuy√™n nghi·ªáp, s·ª≠ d·ª•ng markdown ƒë·ªÉ format ƒë·∫πp."
    )
    
    user_prompt = f"""
Ph√¢n t√≠ch h·ªì s∆° t√≠n d·ª•ng v·ªõi c√°c th√¥ng tin sau:

**B·ªò CH·ªà S·ªê T√ÄI CH√çNH X1-X14:**
{str(data_payload)}

H√£y ph√¢n t√≠ch chi ti·∫øt v√† ƒë∆∞a ra khuy·∫øn ngh·ªã cho vay d·ª±a tr√™n:
- ƒêi·ªÉm m·∫°nh/y·∫øu c·ªßa doanh nghi·ªáp
- M·ª©c ƒë·ªô r·ªßi ro (TH·∫§P/TRUNG B√åNH/CAO)
- Khuy·∫øn ngh·ªã cu·ªëi c√πng: CHO VAY ho·∫∑c KH√îNG CHO VAY
"""

    try:
        response = client.models.generate_content(
            model=MODEL_NAME,
            contents=user_prompt,
            config={
                "system_instruction": sys_prompt,
                "temperature": 0.3,
                "max_output_tokens": 2048,
            }
        )
        return response.text
    except APIError as e:
        return f"‚ùå L·ªói g·ªçi API Gemini: {e}"
    except Exception as e:
        return f"‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"

# =========================
# T√çNH X1..X14 T·ª™ 3 SHEET
# =========================
ALIAS_IS = {
    "doanh_thu_thuan": ["Doanh thu thu·∫ßn", "Doanh thu b√°n h√†ng", "Doanh thu thu·∫ßn v·ªÅ b√°n h√†ng v√† cung c·∫•p d·ªãch v·ª•"],
    "gia_von": ["Gi√° v·ªën h√†ng b√°n"],
    "loi_nhuan_gop": ["L·ª£i nhu·∫≠n g·ªôp"],
    "chi_phi_lai_vay": ["Chi ph√≠ l√£i vay", "Chi ph√≠ t√†i ch√≠nh (trong ƒë√≥: chi ph√≠ l√£i vay)"],
    "loi_nhuan_truoc_thue": ["T·ªïng l·ª£i nhu·∫≠n k·∫ø to√°n tr∆∞·ªõc thu·∫ø", "L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø", "L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø thu nh·∫≠p DN"],
}
ALIAS_BS = {
    "tong_tai_san": ["T·ªïng t√†i s·∫£n"],
    "von_chu_so_huu": ["V·ªën ch·ªß s·ªü h·ªØu", "V·ªën CSH"],
    "no_phai_tra": ["N·ª£ ph·∫£i tr·∫£"],
    "tai_san_ngan_han": ["T√†i s·∫£n ng·∫Øn h·∫°n"],
    "no_ngan_han": ["N·ª£ ng·∫Øn h·∫°n"],
    "hang_ton_kho": ["H√†ng t·ªìn kho"],
    "tien_tdt": ["Ti·ªÅn v√† c√°c kho·∫£n t∆∞∆°ng ƒë∆∞∆°ng ti·ªÅn", "Ti·ªÅn v√† t∆∞∆°ng ƒë∆∞∆°ng ti·ªÅn"],
    "phai_thu_kh": ["Ph·∫£i thu ng·∫Øn h·∫°n c·ªßa kh√°ch h√†ng", "Ph·∫£i thu kh√°ch h√†ng"],
    "no_dai_han_den_han": ["N·ª£ d√†i h·∫°n ƒë·∫øn h·∫°n tr·∫£", "N·ª£ d√†i h·∫°n ƒë·∫øn h·∫°n"],
}
ALIAS_CF = {
    "khau_hao": ["Kh·∫•u hao TSCƒê", "Kh·∫•u hao", "Chi ph√≠ kh·∫•u hao"],
}

def _pick_year_cols(df: pd.DataFrame):
    numeric_years = []
    for c in df.columns[1:]:
        try:
            y = int(float(str(c).strip()))
            if 1990 <= y <= 2100:
                numeric_years.append((y, c))
        except Exception:
            continue
    if numeric_years:
        numeric_years.sort(key=lambda x: x[0])
        return numeric_years[-2][1], numeric_years[-1][1]
    cols = df.columns[-2:]
    return cols[0], cols[1]

def _get_row_vals(df: pd.DataFrame, aliases: list[str]):
    label_col = df.columns[0]
    prev_col, cur_col = _pick_year_cols(df)
    mask = False
    for alias in aliases:
        mask = mask | df[label_col].astype(str).str.contains(alias, case=False, na=False)
    rows = df[mask]
    if rows.empty:
        return np.nan, np.nan
    row = rows.iloc[0]

    def to_num(x):
        try:
            return float(str(x).replace(",", "").replace(" ", ""))
        except Exception:
            return np.nan

    return to_num(row[prev_col]), to_num(row[cur_col])

def compute_ratios_from_three_sheets(xlsx_file) -> pd.DataFrame:
    bs = pd.read_excel(xlsx_file, sheet_name="CDKT", engine="openpyxl")
    is_ = pd.read_excel(xlsx_file, sheet_name="BCTN", engine="openpyxl")
    cf = pd.read_excel(xlsx_file, sheet_name="LCTT", engine="openpyxl")

    DTT_prev, DTT_cur    = _get_row_vals(is_, ALIAS_IS["doanh_thu_thuan"])
    GVHB_prev, GVHB_cur = _get_row_vals(is_, ALIAS_IS["gia_von"])
    LNG_prev, LNG_cur    = _get_row_vals(is_, ALIAS_IS["loi_nhuan_gop"])
    LNTT_prev, LNTT_cur = _get_row_vals(is_, ALIAS_IS["loi_nhuan_truoc_thue"])
    LV_prev, LV_cur      = _get_row_vals(is_, ALIAS_IS["chi_phi_lai_vay"])

    TTS_prev, TTS_cur      = _get_row_vals(bs, ALIAS_BS["tong_tai_san"])
    VCSH_prev, VCSH_cur    = _get_row_vals(bs, ALIAS_BS["von_chu_so_huu"])
    NPT_prev, NPT_cur      = _get_row_vals(bs, ALIAS_BS["no_phai_tra"])
    TSNH_prev, TSNH_cur    = _get_row_vals(bs, ALIAS_BS["tai_san_ngan_han"])
    NNH_prev, NNH_cur      = _get_row_vals(bs, ALIAS_BS["no_ngan_han"])
    HTK_prev, HTK_cur      = _get_row_vals(bs, ALIAS_BS["hang_ton_kho"])
    Tien_prev, Tien_cur    = _get_row_vals(bs, ALIAS_BS["tien_tdt"])
    KPT_prev, KPT_cur      = _get_row_vals(bs, ALIAS_BS["phai_thu_kh"])
    NDH_prev, NDH_cur      = _get_row_vals(bs, ALIAS_BS["no_dai_han_den_han"])

    KH_prev, KH_cur = _get_row_vals(cf, ALIAS_CF["khau_hao"])

    if pd.notna(GVHB_cur): GVHB_cur = abs(GVHB_cur)
    if pd.notna(LV_cur):    LV_cur    = abs(LV_cur)
    if pd.notna(KH_cur):    KH_cur    = abs(KH_cur)

    def avg(a, b):
        if pd.isna(a) and pd.isna(b): return np.nan
        if pd.isna(a): return b
        if pd.isna(b): return a
        return (a + b) / 2.0
    
    TTS_avg  = avg(TTS_cur,  TTS_prev)
    VCSH_avg = avg(VCSH_cur, VCSH_prev)
    HTK_avg  = avg(HTK_cur,  HTK_prev)
    KPT_avg  = avg(KPT_cur,  KPT_prev)

    EBIT_cur = (LNTT_cur + LV_cur) if (pd.notna(LNTT_cur) and pd.notna(LV_cur)) else np.nan
    NDH_cur = 0.0 if pd.isna(NDH_cur) else NDH_cur

    def div(a, b):
        return np.nan if (b is None or pd.isna(b) or b == 0) else a / b

    X1  = div(LNG_cur, DTT_cur)
    X2  = div(LNTT_cur, DTT_cur)
    X3  = div(LNTT_cur, TTS_avg)
    X4  = div(LNTT_cur, VCSH_avg)
    X5  = div(NPT_cur,  TTS_cur)
    X6  = div(NPT_cur,  VCSH_cur)
    X7  = div(TSNH_cur, NNH_cur)
    X8  = div((TSNH_cur - HTK_cur) if pd.notna(TSNH_cur) and pd.notna(HTK_cur) else np.nan, NNH_cur)
    X9  = div(EBIT_cur, LV_cur)
    X10 = div((EBIT_cur + (KH_cur if pd.notna(KH_cur) else 0.0)),
              (LV_cur + NDH_cur) if pd.notna(LV_cur) else np.nan)
    X11 = div(Tien_cur, VCSH_cur)
    X12 = div(GVHB_cur, HTK_avg)
    turnover = div(DTT_cur, KPT_avg)
    X13 = div(365.0, turnover) if pd.notna(turnover) and turnover != 0 else np.nan
    X14 = div(DTT_cur, TTS_avg)

    ratios = pd.DataFrame([[X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14]],
                          columns=[f"X_{i}" for i in range(1, 15)])
    return ratios

# =========================
# GIAO DI·ªÜN CH√çNH
# =========================
np.random.seed(0)

# ·∫®N TI√äU ƒê·ªÄ CH√çNH (ch·ªâ hi·ªán trong sidebar)
st.sidebar.title("üè¶ D·ª∞ B√ÅO PD")
st.sidebar.caption("D·ª± b√°o x√°c su·∫•t v·ª° n·ª£ kh√°ch h√†ng")

st.caption("üîé Tr·∫°ng th√°i Gemini: " + ("‚úÖ s·∫µn s√†ng" if _GEMINI_OK else "‚ö†Ô∏è Thi·∫øu th∆∞ vi·ªán google-genai"))

# Load CSV hu·∫•n luy·ªán
try:
    df = pd.read_csv('DATASET.csv', encoding='latin-1')
except Exception:
    df = None

uploaded_file = st.file_uploader("üìä T·∫£i CSV d·ªØ li·ªáu hu·∫•n luy·ªán", type=['csv'])
if uploaded_file is not None:
    df = pd.read_csv(uploaded_file, encoding='latin-1')

if df is None:
    st.info("H√£y t·∫£i file CSV hu·∫•n luy·ªán (c√≥ c·ªôt 'default' v√† X_1...X_14).")
    st.stop()

required_cols = ['default'] + [f"X_{i}" for i in range(1, 15)]
missing = [c for c in required_cols if c not in df.columns]
if missing:
    st.error(f"Thi·∫øu c·ªôt: {missing}")
    st.stop()

st.write(df[[f"X_{i}" for i in range(1, 15)]].describe())

# Train model
X = df.drop(columns=['default'])
y = df['default'].astype(int)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
model = LogisticRegression(random_state=42, max_iter=1000, class_weight="balanced", solver="lbfgs")
model.fit(X_train, y_train)

y_pred_in = model.predict(X_train)
y_proba_in = model.predict_proba(X_train)[:, 1]
y_pred_out = model.predict(X_test)
y_proba_out = model.predict_proba(X_test)[:, 1]

metrics_in = {
    "accuracy_in": accuracy_score(y_train, y_pred_in),
    "precision_in": precision_score(y_train, y_pred_in, zero_division=0),
    "recall_in": recall_score(y_train, y_pred_in, zero_division=0),
    "f1_in": f1_score(y_train, y_pred_in, zero_division=0),
    "auc_in": roc_auc_score(y_train, y_proba_in),
}
metrics_out = {
    "accuracy_out": accuracy_score(y_test, y_pred_out),
    "precision_out": precision_score(y_test, y_pred_out, zero_division=0),
    "recall_out": recall_score(y_test, y_pred_out, zero_division=0),
    "f1_out": f1_score(y_test, y_pred_out, zero_division=0),
    "auc_out": roc_auc_score(y_test, y_proba_out),
}

# MENU
menu = ["M·ª•c ti√™u c·ªßa m√¥ h√¨nh", "X√¢y d·ª±ng m√¥ h√¨nh", "S·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ d·ª± b√°o"]
choice = st.sidebar.selectbox('üìã Danh m·ª•c t√≠nh nƒÉng', menu)

if choice == 'M·ª•c ti√™u c·ªßa m√¥ h√¨nh':
    st.title("üéØ M·ª•c ti√™u c·ªßa m√¥ h√¨nh")
    st.markdown("**D·ª± b√°o x√°c su·∫•t v·ª° n·ª£ (PD)** c·ªßa kh√°ch h√†ng doanh nghi·ªáp d·ª±a tr√™n X1‚ÄìX14.")
    for img in ["hinh2.jpg", "LogReg_1.png", "hinh3.png"]:
        try:
            st.image(img)
        except Exception:
            st.warning(f"Kh√¥ng t√¨m th·∫•y {img}")

elif choice == 'X√¢y d·ª±ng m√¥ h√¨nh':
    st.title("üîß X√¢y d·ª±ng m√¥ h√¨nh")
    
    st.write("##### 1) Hi·ªÉn th·ªã d·ªØ li·ªáu")
    st.dataframe(df.head(3))
    st.dataframe(df.tail(3))
    
    st.write("##### 2) Tr·ª±c quan h√≥a d·ªØ li·ªáu")
    col = st.text_input('Nh·∫≠p t√™n bi·∫øn X mu·ªën v·∫Ω', value='X_1')
    if col in df.columns:
        try:
            fig, ax = plt.subplots(figsize=(8, 5))
            sns.scatterplot(data=df, x=col, y='default', alpha=0.4, ax=ax)
            x_range = np.linspace(df[col].min(), df[col].max(), 100)
            X_temp = df[[col]].copy()
            y_temp = df['default']
            lr_temp = LogisticRegression(max_iter=1000)
            lr_temp.fit(X_temp, y_temp)
            x_test = pd.DataFrame({col: x_range})
            y_curve = lr_temp.predict_proba(x_test)[:, 1]
            ax.plot(x_range, y_curve, color='red', linewidth=2)
            ax.set_ylabel('X√°c su·∫•t default')
            ax.set_xlabel(col)
            st.pyplot(fig)
            plt.close()
        except Exception as e:
            st.error(f"L·ªói v·∫Ω bi·ªÉu ƒë·ªì: {e}")
    else:
        st.warning("Bi·∫øn kh√¥ng t·ªìn t·∫°i.")
    
    st.write("##### 3) K·∫øt qu·∫£ ƒë√°nh gi√°")
    dt = pd.DataFrame([metrics_in | metrics_out])
    st.dataframe(dt)
    
    st.write("##### 4) Ma tr·∫≠n nh·∫ßm l·∫´n (test)")
    cm = confusion_matrix(y_test, y_pred_out)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    fig2, ax = plt.subplots()
    disp.plot(ax=ax)
    st.pyplot(fig2)
    plt.close()

elif choice == 'S·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ d·ª± b√°o':
    # =====================================
    # GIAO DI·ªÜN N√ÇNG C·∫§P - ·∫®N TI√äU ƒê·ªÄ CH√çNH
    # =====================================
    
    st.markdown("""
    <style>
    .big-font {
        font-size: 20px !important;
        font-weight: bold;
        color: #1f77b4;
    }
    .metric-box {
        padding: 20px;
        border-radius: 10px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        text-align: center;
        margin: 10px 0;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Upload file - Giao di·ªán ƒë·∫πp h∆°n
    st.markdown("### üìÇ T·∫£i h·ªì s∆° t√†i ch√≠nh")
    st.caption("File Excel ph·∫£i c√≥ ƒë·ªß 3 sheet: **CDKT** | **BCTN** | **LCTT**")
    
    up_xlsx = st.file_uploader("", type=["xlsx"], key="ho_so_dn", label_visibility="collapsed")
    
    if up_xlsx is not None:
        # T√≠nh X1..X14
        try:
            ratios_df = compute_ratios_from_three_sheets(up_xlsx)
        except Exception as e:
            st.error(f"‚ùå L·ªói t√≠nh X1‚Ä¶X14: {e}")
            st.stop()

        # Hi·ªÉn th·ªã k·∫øt qu·∫£ trong tabs
        tab1, tab2, tab3 = st.tabs(["üìä Ch·ªâ s·ªë X1-X14", "üéØ D·ª± b√°o PD", "ü§ñ Ph√¢n t√≠ch AI"])
        
        with tab1:
            st.markdown("#### B·ªô ch·ªâ s·ªë t√†i ch√≠nh")
            st.dataframe(ratios_df.style.format("{:.4f}"), use_container_width=True)
            
            # Gi·∫£i th√≠ch ch·ªâ s·ªë
            with st.expander("‚ÑπÔ∏è √ù nghƒ©a c√°c ch·ªâ s·ªë"):
                st.markdown("""
                - **X1**: Bi√™n l·ª£i nhu·∫≠n g·ªôp | **X2**: Bi√™n LNTT | **X3**: ROA | **X4**: ROE
                - **X5**: N·ª£/T√†i s·∫£n | **X6**: N·ª£/VCSH | **X7**: Thanh to√°n hi·ªán h√†nh | **X8**: Thanh to√°n nhanh
                - **X9**: Kh·∫£ nƒÉng tr·∫£ l√£i | **X10**: Kh·∫£ nƒÉng tr·∫£ n·ª£ g·ªëc | **X11**: Ti·ªÅn/VCSH
                - **X12**: V√≤ng quay HTK | **X13**: K·ª≥ thu ti·ªÅn BQ | **X14**: Hi·ªáu su·∫•t t√†i s·∫£n
                """)
        
        with tab2:
            st.markdown("#### K·∫øt qu·∫£ d·ª± b√°o x√°c su·∫•t v·ª° n·ª£")
            
            if set(X.columns) == set(ratios_df.columns):
                try:
                    probs = model.predict_proba(ratios_df[X.columns])[:, 1]
                    preds = (probs >= 0.5).astype(int)
                    
                    # Hi·ªÉn th·ªã metrics ƒë·∫πp
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric(
                            label="X√°c su·∫•t v·ª° n·ª£ (PD)",
                            value=f"{probs[0]:.1%}",
                            delta=f"{probs[0]*100:.1f}% ƒëi·ªÉm" if probs[0] > 0.5 else None
                        )
                    
                    with col2:
                        pred_text = "üî¥ V·ª† N·ª¢" if preds[0] == 1 else "üü¢ AN TO√ÄN"
                        st.metric(label="K·∫øt lu·∫≠n", value=pred_text)
                    
                    with col3:
                        if probs[0] < 0.3:
                            risk = "üü¢ TH·∫§P"
                        elif probs[0] < 0.5:
                            risk = "üü° TRUNG B√åNH"
                        else:
                            risk = "üî¥ CAO"
                        st.metric(label="M·ª©c ƒë·ªô r·ªßi ro", value=risk)
                    
                    # Progress bar
                    st.markdown("##### Thang ƒë√°nh gi√° r·ªßi ro")
                    st.progress(probs[0])
                    
                    # Chi ti·∫øt ph√¢n t√≠ch
                    if probs[0] < 0.3:
                        st.success("‚úÖ **ƒê√ÅNH GI√Å**: R·ªßi ro th·∫•p, kh·∫£ nƒÉng cho vay t·ªët.")
                    elif probs[0] < 0.5:
                        st.warning("‚ö†Ô∏è **ƒê√ÅNH GI√Å**: R·ªßi ro trung b√¨nh, c·∫ßn xem x√©t th√™m ƒëi·ªÅu ki·ªán ƒë·∫£m b·∫£o.")
                    else:
                        st.error("üö´ **ƒê√ÅNH GI√Å**: R·ªßi ro cao, khuy·∫øn ngh·ªã kh√¥ng cho vay ho·∫∑c y√™u c·∫ßu t√†i s·∫£n th·∫ø ch·∫•p cao.")
                    
                    # B·∫£ng chi ti·∫øt
                    show = ratios_df.copy()
                    show["PD (%)"] = probs * 100
                    show["D·ª± b√°o"] = ["V·ª† N·ª¢" if p == 1 else "AN TO√ÄN" for p in preds]
                    st.dataframe(show.style.format({
                        **{f"X_{i}": "{:.4f}" for i in range(1, 15)},
                        "PD (%)": "{:.2f}%"
                    }), use_container_width=True)
                    
                    # L∆∞u data cho AI
                    data_for_ai = ratios_df.iloc[0].to_dict()
                    data_for_ai['PD_Probability'] = probs[0]
                    data_for_ai['PD_Prediction'] = "Default (V·ª° n·ª£)" if preds[0] == 1 else "Non-Default (Kh√¥ng v·ª° n·ª£)"
                    
                except Exception as e:
                    st.warning(f"Kh√¥ng d·ª± b√°o ƒë∆∞·ª£c PD: {e}")
                    data_for_ai = ratios_df.iloc[0].to_dict()
            else:
                st.error("‚ö†Ô∏è C·∫•u tr√∫c X_1..X_14 kh√¥ng kh·ªõp v·ªõi m√¥ h√¨nh.")
                data_for_ai = ratios_df.iloc[0].to_dict()
        
        with tab3:
            st.markdown("#### Ph√¢n t√≠ch chuy√™n s√¢u b·∫±ng Gemini AI")
            
            if st.button("üöÄ Y√™u c·∫ßu Gemini AI Ph√¢n t√≠ch", type="primary", use_container_width=True):
                api_key = st.secrets.get("GEMINI_API_KEY")
                
                if api_key:
                    with st.spinner('‚è≥ Gemini AI ƒëang ph√¢n t√≠ch h·ªì s∆° t√≠n d·ª•ng...'):
                        ai_result = get_ai_analysis(data_for_ai, api_key)
                        st.markdown("---")
                        st.markdown("##### üìã B√°o c√°o ph√¢n t√≠ch t·ª´ Gemini AI")
                        st.markdown(ai_result)
                else:
                    st.error("‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y **GEMINI_API_KEY** trong Streamlit Secrets.")
                    st.info("Vui l√≤ng c·∫•u h√¨nh API key t·∫°i: Settings ‚Üí Secrets")
    else:
        # H∆∞·ªõng d·∫´n khi ch∆∞a upload
        st.info("üìÅ Vui l√≤ng t·∫£i file **ho_so_dn.xlsx** ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch")
        
        with st.expander("üìñ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng"):
            st.markdown("""
            ### C·∫•u tr√∫c file Excel y√™u c·∫ßu:
            
            **1. Sheet CDKT** (C√¢n ƒë·ªëi k·∫ø to√°n):
            - T·ªïng t√†i s·∫£n, V·ªën ch·ªß s·ªü h·ªØu, N·ª£ ph·∫£i tr·∫£
            - T√†i s·∫£n ng·∫Øn h·∫°n, N·ª£ ng·∫Øn h·∫°n, H√†ng t·ªìn kho
            - Ti·ªÅn v√† t∆∞∆°ng ƒë∆∞∆°ng ti·ªÅn, Ph·∫£i thu kh√°ch h√†ng
            
            **2. Sheet BCTN** (B√°o c√°o thu nh·∫≠p):
            - Doanh thu thu·∫ßn, Gi√° v·ªën h√†ng b√°n, L·ª£i nhu·∫≠n g·ªôp
            - Chi ph√≠ l√£i vay, L·ª£i nhu·∫≠n tr∆∞·ªõc thu·∫ø
            
            **3. Sheet LCTT** (L∆∞u chuy·ªÉn ti·ªÅn t·ªá):
            - Kh·∫•u hao TSCƒê
            
            ### C·∫•u h√¨nh Gemini API:
            1. L·∫•y API key t·∫°i: https://aistudio.google.com/apikey
            2. Th√™m v√†o Secrets: `GEMINI_API_KEY = "your-key"`
            """)
